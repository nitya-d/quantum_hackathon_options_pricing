{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a758c93e",
   "metadata": {},
   "source": [
    "# Baseline QML Option Pricing (Quandela Challenge_Swaptions)\n",
    "\n",
    "This notebook provides a clean baseline for the hackathon task:\n",
    "- Load and inspect the Hugging Face dataset.\n",
    "- Build a robust preprocessing pipeline.\n",
    "- Train a hybrid QML model (MerLin quantum layer + classical head).\n",
    "- Evaluate and generate predictions for the test split.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f78a61a",
   "metadata": {},
   "source": [
    "## 0) Environment\n",
    "\n",
    "Install missing packages only if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional install cell (uncomment if your environment is missing packages)\n",
    "# %pip install -U merlinquantum datasets scikit-learn pandas matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de40f0",
   "metadata": {},
   "source": [
    "## 1) Imports and Reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ea0b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from merlin import LexGrouping, QuantumLayer\n",
    "from merlin.builder import CircuitBuilder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d978a9c3",
   "metadata": {},
   "source": [
    "## 2) Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b421fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Date', 'Tenor : 1; Maturity : 0.0833333333333333', 'Tenor : 2; Maturity : 0.0833333333333333', 'Tenor : 3; Maturity : 0.0833333333333333', 'Tenor : 4; Maturity : 0.0833333333333333', 'Tenor : 5; Maturity : 0.0833333333333333', 'Tenor : 6; Maturity : 0.0833333333333333', 'Tenor : 7; Maturity : 0.0833333333333333', 'Tenor : 8; Maturity : 0.0833333333333333', 'Tenor : 9; Maturity : 0.0833333333333333', 'Tenor : 10; Maturity : 0.0833333333333333', 'Tenor : 15; Maturity : 0.0833333333333333', 'Tenor : 20; Maturity : 0.0833333333333333', 'Tenor : 25; Maturity : 0.0833333333333333', 'Tenor : 30; Maturity : 0.0833333333333333', 'Tenor : 1; Maturity : 0.25', 'Tenor : 2; Maturity : 0.25', 'Tenor : 3; Maturity : 0.25', 'Tenor : 4; Maturity : 0.25', 'Tenor : 5; Maturity : 0.25', 'Tenor : 6; Maturity : 0.25', 'Tenor : 7; Maturity : 0.25', 'Tenor : 8; Maturity : 0.25', 'Tenor : 9; Maturity : 0.25', 'Tenor : 10; Maturity : 0.25', 'Tenor : 15; Maturity : 0.25', 'Tenor : 20; Maturity : 0.25', 'Tenor : 25; Maturity : 0.25', 'Tenor : 30; Maturity : 0.25', 'Tenor : 1; Maturity : 0.5', 'Tenor : 2; Maturity : 0.5', 'Tenor : 3; Maturity : 0.5', 'Tenor : 4; Maturity : 0.5', 'Tenor : 5; Maturity : 0.5', 'Tenor : 6; Maturity : 0.5', 'Tenor : 7; Maturity : 0.5', 'Tenor : 8; Maturity : 0.5', 'Tenor : 9; Maturity : 0.5', 'Tenor : 10; Maturity : 0.5', 'Tenor : 15; Maturity : 0.5', 'Tenor : 20; Maturity : 0.5', 'Tenor : 25; Maturity : 0.5', 'Tenor : 30; Maturity : 0.5', 'Tenor : 1; Maturity : 0.75', 'Tenor : 2; Maturity : 0.75', 'Tenor : 3; Maturity : 0.75', 'Tenor : 4; Maturity : 0.75', 'Tenor : 5; Maturity : 0.75', 'Tenor : 6; Maturity : 0.75', 'Tenor : 7; Maturity : 0.75', 'Tenor : 8; Maturity : 0.75', 'Tenor : 9; Maturity : 0.75', 'Tenor : 10; Maturity : 0.75', 'Tenor : 15; Maturity : 0.75', 'Tenor : 20; Maturity : 0.75', 'Tenor : 25; Maturity : 0.75', 'Tenor : 30; Maturity : 0.75', 'Tenor : 1; Maturity : 1', 'Tenor : 2; Maturity : 1', 'Tenor : 3; Maturity : 1', 'Tenor : 4; Maturity : 1', 'Tenor : 5; Maturity : 1', 'Tenor : 6; Maturity : 1', 'Tenor : 7; Maturity : 1', 'Tenor : 8; Maturity : 1', 'Tenor : 9; Maturity : 1', 'Tenor : 10; Maturity : 1', 'Tenor : 15; Maturity : 1', 'Tenor : 20; Maturity : 1', 'Tenor : 25; Maturity : 1', 'Tenor : 30; Maturity : 1', 'Tenor : 1; Maturity : 1.5', 'Tenor : 2; Maturity : 1.5', 'Tenor : 3; Maturity : 1.5', 'Tenor : 4; Maturity : 1.5', 'Tenor : 5; Maturity : 1.5', 'Tenor : 6; Maturity : 1.5', 'Tenor : 7; Maturity : 1.5', 'Tenor : 8; Maturity : 1.5', 'Tenor : 9; Maturity : 1.5', 'Tenor : 10; Maturity : 1.5', 'Tenor : 15; Maturity : 1.5', 'Tenor : 20; Maturity : 1.5', 'Tenor : 25; Maturity : 1.5', 'Tenor : 30; Maturity : 1.5', 'Tenor : 1; Maturity : 2', 'Tenor : 2; Maturity : 2', 'Tenor : 3; Maturity : 2', 'Tenor : 4; Maturity : 2', 'Tenor : 5; Maturity : 2', 'Tenor : 6; Maturity : 2', 'Tenor : 7; Maturity : 2', 'Tenor : 8; Maturity : 2', 'Tenor : 9; Maturity : 2', 'Tenor : 10; Maturity : 2', 'Tenor : 15; Maturity : 2', 'Tenor : 20; Maturity : 2', 'Tenor : 25; Maturity : 2', 'Tenor : 30; Maturity : 2', 'Tenor : 1; Maturity : 3', 'Tenor : 2; Maturity : 3', 'Tenor : 3; Maturity : 3', 'Tenor : 4; Maturity : 3', 'Tenor : 5; Maturity : 3', 'Tenor : 6; Maturity : 3', 'Tenor : 7; Maturity : 3', 'Tenor : 8; Maturity : 3', 'Tenor : 9; Maturity : 3', 'Tenor : 10; Maturity : 3', 'Tenor : 15; Maturity : 3', 'Tenor : 20; Maturity : 3', 'Tenor : 25; Maturity : 3', 'Tenor : 30; Maturity : 3', 'Tenor : 1; Maturity : 4', 'Tenor : 2; Maturity : 4', 'Tenor : 3; Maturity : 4', 'Tenor : 4; Maturity : 4', 'Tenor : 5; Maturity : 4', 'Tenor : 6; Maturity : 4', 'Tenor : 7; Maturity : 4', 'Tenor : 8; Maturity : 4', 'Tenor : 9; Maturity : 4', 'Tenor : 10; Maturity : 4', 'Tenor : 15; Maturity : 4', 'Tenor : 20; Maturity : 4', 'Tenor : 25; Maturity : 4', 'Tenor : 30; Maturity : 4', 'Tenor : 1; Maturity : 5', 'Tenor : 2; Maturity : 5', 'Tenor : 3; Maturity : 5', 'Tenor : 4; Maturity : 5', 'Tenor : 5; Maturity : 5', 'Tenor : 6; Maturity : 5', 'Tenor : 7; Maturity : 5', 'Tenor : 8; Maturity : 5', 'Tenor : 9; Maturity : 5', 'Tenor : 10; Maturity : 5', 'Tenor : 15; Maturity : 5', 'Tenor : 20; Maturity : 5', 'Tenor : 25; Maturity : 5', 'Tenor : 30; Maturity : 5', 'Tenor : 1; Maturity : 7', 'Tenor : 2; Maturity : 7', 'Tenor : 3; Maturity : 7', 'Tenor : 4; Maturity : 7', 'Tenor : 5; Maturity : 7', 'Tenor : 6; Maturity : 7', 'Tenor : 7; Maturity : 7', 'Tenor : 8; Maturity : 7', 'Tenor : 9; Maturity : 7', 'Tenor : 10; Maturity : 7', 'Tenor : 15; Maturity : 7', 'Tenor : 20; Maturity : 7', 'Tenor : 25; Maturity : 7', 'Tenor : 30; Maturity : 7', 'Tenor : 1; Maturity : 10', 'Tenor : 2; Maturity : 10', 'Tenor : 3; Maturity : 10', 'Tenor : 4; Maturity : 10', 'Tenor : 5; Maturity : 10', 'Tenor : 6; Maturity : 10', 'Tenor : 7; Maturity : 10', 'Tenor : 8; Maturity : 10', 'Tenor : 9; Maturity : 10', 'Tenor : 10; Maturity : 10', 'Tenor : 15; Maturity : 10', 'Tenor : 20; Maturity : 10', 'Tenor : 25; Maturity : 10', 'Tenor : 30; Maturity : 10', 'Tenor : 1; Maturity : 15', 'Tenor : 2; Maturity : 15', 'Tenor : 3; Maturity : 15', 'Tenor : 4; Maturity : 15', 'Tenor : 5; Maturity : 15', 'Tenor : 6; Maturity : 15', 'Tenor : 7; Maturity : 15', 'Tenor : 8; Maturity : 15', 'Tenor : 9; Maturity : 15', 'Tenor : 10; Maturity : 15', 'Tenor : 15; Maturity : 15', 'Tenor : 20; Maturity : 15', 'Tenor : 25; Maturity : 15', 'Tenor : 30; Maturity : 15', 'Tenor : 1; Maturity : 20', 'Tenor : 2; Maturity : 20', 'Tenor : 3; Maturity : 20', 'Tenor : 4; Maturity : 20', 'Tenor : 5; Maturity : 20', 'Tenor : 6; Maturity : 20', 'Tenor : 7; Maturity : 20', 'Tenor : 8; Maturity : 20', 'Tenor : 9; Maturity : 20', 'Tenor : 10; Maturity : 20', 'Tenor : 15; Maturity : 20', 'Tenor : 20; Maturity : 20', 'Tenor : 25; Maturity : 20', 'Tenor : 30; Maturity : 20', 'Tenor : 1; Maturity : 25', 'Tenor : 2; Maturity : 25', 'Tenor : 3; Maturity : 25', 'Tenor : 4; Maturity : 25', 'Tenor : 5; Maturity : 25', 'Tenor : 6; Maturity : 25', 'Tenor : 7; Maturity : 25', 'Tenor : 8; Maturity : 25', 'Tenor : 9; Maturity : 25', 'Tenor : 10; Maturity : 25', 'Tenor : 15; Maturity : 25', 'Tenor : 20; Maturity : 25', 'Tenor : 25; Maturity : 25', 'Tenor : 30; Maturity : 25', 'Tenor : 1; Maturity : 30', 'Tenor : 2; Maturity : 30', 'Tenor : 3; Maturity : 30', 'Tenor : 4; Maturity : 30', 'Tenor : 5; Maturity : 30', 'Tenor : 6; Maturity : 30', 'Tenor : 7; Maturity : 30', 'Tenor : 8; Maturity : 30', 'Tenor : 9; Maturity : 30', 'Tenor : 10; Maturity : 30', 'Tenor : 15; Maturity : 30', 'Tenor : 20; Maturity : 30', 'Tenor : 25; Maturity : 30', 'Tenor : 30; Maturity : 30'],\n",
      "        num_rows: 983\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "DATASET_ID = \"Quandela/Challenge_Swaptions\"\n",
    "\n",
    "ds = load_dataset(DATASET_ID)\n",
    "print(ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58553ae",
   "metadata": {},
   "source": [
    "## 3) Helper Functions (Split + Target Detection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8149c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_train_split(dataset_dict: DatasetDict):\n",
    "    if \"train\" in dataset_dict:\n",
    "        return \"train\"\n",
    "    return list(dataset_dict.keys())[0]\n",
    "\n",
    "\n",
    "def pick_test_split(dataset_dict: DatasetDict):\n",
    "    for name in [\"test\", \"public_test\", \"validation\"]:\n",
    "        if name in dataset_dict:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "\n",
    "def infer_target_columns(df: pd.DataFrame):\n",
    "    explicit_pairs = [\n",
    "        (\"call_price\", \"put_price\"),\n",
    "        (\"call\", \"put\"),\n",
    "        (\"price_call\", \"price_put\"),\n",
    "        (\"call_option_price\", \"put_option_price\"),\n",
    "        (\"price_call_option\", \"price_put_option\"),\n",
    "    ]\n",
    "    cols = set(df.columns)\n",
    "    for c1, c2 in explicit_pairs:\n",
    "        if c1 in cols and c2 in cols:\n",
    "            return [c1, c2]\n",
    "\n",
    "    numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    call_like = [c for c in numeric_cols if \"call\" in c.lower()]\n",
    "    put_like = [c for c in numeric_cols if \"put\" in c.lower()]\n",
    "\n",
    "    if call_like and put_like:\n",
    "        return [call_like[0], put_like[0]]\n",
    "\n",
    "    # Conservative fallback: use last two numeric columns.\n",
    "    # This keeps notebook runnable even when columns are named generically.\n",
    "    if len(numeric_cols) >= 2:\n",
    "        print(\"Warning: using fallback target inference (last two numeric columns).\")\n",
    "        print(\"Numeric columns:\", numeric_cols)\n",
    "        return numeric_cols[-2:]\n",
    "\n",
    "    raise ValueError(\n",
    "        \"Could not infer call/put target columns automatically. \"\n",
    "        \"Please set TARGET_COLS manually after inspecting columns.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def dataset_to_df(split_ds: Dataset) -> pd.DataFrame:\n",
    "    return split_ds.to_pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b1ae1",
   "metadata": {},
   "source": [
    "## 4) Build Train/Validation/Test DataFrames\n",
    "\n",
    "If the dataset only contains a training split, we create our own train/validation/test split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b79ea538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split: train\n",
      "Shape: (983, 225)\n",
      "Columns: ['Date', 'Tenor : 1; Maturity : 0.0833333333333333', 'Tenor : 2; Maturity : 0.0833333333333333', 'Tenor : 3; Maturity : 0.0833333333333333', 'Tenor : 4; Maturity : 0.0833333333333333', 'Tenor : 5; Maturity : 0.0833333333333333', 'Tenor : 6; Maturity : 0.0833333333333333', 'Tenor : 7; Maturity : 0.0833333333333333', 'Tenor : 8; Maturity : 0.0833333333333333', 'Tenor : 9; Maturity : 0.0833333333333333', 'Tenor : 10; Maturity : 0.0833333333333333', 'Tenor : 15; Maturity : 0.0833333333333333', 'Tenor : 20; Maturity : 0.0833333333333333', 'Tenor : 25; Maturity : 0.0833333333333333', 'Tenor : 30; Maturity : 0.0833333333333333', 'Tenor : 1; Maturity : 0.25', 'Tenor : 2; Maturity : 0.25', 'Tenor : 3; Maturity : 0.25', 'Tenor : 4; Maturity : 0.25', 'Tenor : 5; Maturity : 0.25', 'Tenor : 6; Maturity : 0.25', 'Tenor : 7; Maturity : 0.25', 'Tenor : 8; Maturity : 0.25', 'Tenor : 9; Maturity : 0.25', 'Tenor : 10; Maturity : 0.25', 'Tenor : 15; Maturity : 0.25', 'Tenor : 20; Maturity : 0.25', 'Tenor : 25; Maturity : 0.25', 'Tenor : 30; Maturity : 0.25', 'Tenor : 1; Maturity : 0.5', 'Tenor : 2; Maturity : 0.5', 'Tenor : 3; Maturity : 0.5', 'Tenor : 4; Maturity : 0.5', 'Tenor : 5; Maturity : 0.5', 'Tenor : 6; Maturity : 0.5', 'Tenor : 7; Maturity : 0.5', 'Tenor : 8; Maturity : 0.5', 'Tenor : 9; Maturity : 0.5', 'Tenor : 10; Maturity : 0.5', 'Tenor : 15; Maturity : 0.5', 'Tenor : 20; Maturity : 0.5', 'Tenor : 25; Maturity : 0.5', 'Tenor : 30; Maturity : 0.5', 'Tenor : 1; Maturity : 0.75', 'Tenor : 2; Maturity : 0.75', 'Tenor : 3; Maturity : 0.75', 'Tenor : 4; Maturity : 0.75', 'Tenor : 5; Maturity : 0.75', 'Tenor : 6; Maturity : 0.75', 'Tenor : 7; Maturity : 0.75', 'Tenor : 8; Maturity : 0.75', 'Tenor : 9; Maturity : 0.75', 'Tenor : 10; Maturity : 0.75', 'Tenor : 15; Maturity : 0.75', 'Tenor : 20; Maturity : 0.75', 'Tenor : 25; Maturity : 0.75', 'Tenor : 30; Maturity : 0.75', 'Tenor : 1; Maturity : 1', 'Tenor : 2; Maturity : 1', 'Tenor : 3; Maturity : 1', 'Tenor : 4; Maturity : 1', 'Tenor : 5; Maturity : 1', 'Tenor : 6; Maturity : 1', 'Tenor : 7; Maturity : 1', 'Tenor : 8; Maturity : 1', 'Tenor : 9; Maturity : 1', 'Tenor : 10; Maturity : 1', 'Tenor : 15; Maturity : 1', 'Tenor : 20; Maturity : 1', 'Tenor : 25; Maturity : 1', 'Tenor : 30; Maturity : 1', 'Tenor : 1; Maturity : 1.5', 'Tenor : 2; Maturity : 1.5', 'Tenor : 3; Maturity : 1.5', 'Tenor : 4; Maturity : 1.5', 'Tenor : 5; Maturity : 1.5', 'Tenor : 6; Maturity : 1.5', 'Tenor : 7; Maturity : 1.5', 'Tenor : 8; Maturity : 1.5', 'Tenor : 9; Maturity : 1.5', 'Tenor : 10; Maturity : 1.5', 'Tenor : 15; Maturity : 1.5', 'Tenor : 20; Maturity : 1.5', 'Tenor : 25; Maturity : 1.5', 'Tenor : 30; Maturity : 1.5', 'Tenor : 1; Maturity : 2', 'Tenor : 2; Maturity : 2', 'Tenor : 3; Maturity : 2', 'Tenor : 4; Maturity : 2', 'Tenor : 5; Maturity : 2', 'Tenor : 6; Maturity : 2', 'Tenor : 7; Maturity : 2', 'Tenor : 8; Maturity : 2', 'Tenor : 9; Maturity : 2', 'Tenor : 10; Maturity : 2', 'Tenor : 15; Maturity : 2', 'Tenor : 20; Maturity : 2', 'Tenor : 25; Maturity : 2', 'Tenor : 30; Maturity : 2', 'Tenor : 1; Maturity : 3', 'Tenor : 2; Maturity : 3', 'Tenor : 3; Maturity : 3', 'Tenor : 4; Maturity : 3', 'Tenor : 5; Maturity : 3', 'Tenor : 6; Maturity : 3', 'Tenor : 7; Maturity : 3', 'Tenor : 8; Maturity : 3', 'Tenor : 9; Maturity : 3', 'Tenor : 10; Maturity : 3', 'Tenor : 15; Maturity : 3', 'Tenor : 20; Maturity : 3', 'Tenor : 25; Maturity : 3', 'Tenor : 30; Maturity : 3', 'Tenor : 1; Maturity : 4', 'Tenor : 2; Maturity : 4', 'Tenor : 3; Maturity : 4', 'Tenor : 4; Maturity : 4', 'Tenor : 5; Maturity : 4', 'Tenor : 6; Maturity : 4', 'Tenor : 7; Maturity : 4', 'Tenor : 8; Maturity : 4', 'Tenor : 9; Maturity : 4', 'Tenor : 10; Maturity : 4', 'Tenor : 15; Maturity : 4', 'Tenor : 20; Maturity : 4', 'Tenor : 25; Maturity : 4', 'Tenor : 30; Maturity : 4', 'Tenor : 1; Maturity : 5', 'Tenor : 2; Maturity : 5', 'Tenor : 3; Maturity : 5', 'Tenor : 4; Maturity : 5', 'Tenor : 5; Maturity : 5', 'Tenor : 6; Maturity : 5', 'Tenor : 7; Maturity : 5', 'Tenor : 8; Maturity : 5', 'Tenor : 9; Maturity : 5', 'Tenor : 10; Maturity : 5', 'Tenor : 15; Maturity : 5', 'Tenor : 20; Maturity : 5', 'Tenor : 25; Maturity : 5', 'Tenor : 30; Maturity : 5', 'Tenor : 1; Maturity : 7', 'Tenor : 2; Maturity : 7', 'Tenor : 3; Maturity : 7', 'Tenor : 4; Maturity : 7', 'Tenor : 5; Maturity : 7', 'Tenor : 6; Maturity : 7', 'Tenor : 7; Maturity : 7', 'Tenor : 8; Maturity : 7', 'Tenor : 9; Maturity : 7', 'Tenor : 10; Maturity : 7', 'Tenor : 15; Maturity : 7', 'Tenor : 20; Maturity : 7', 'Tenor : 25; Maturity : 7', 'Tenor : 30; Maturity : 7', 'Tenor : 1; Maturity : 10', 'Tenor : 2; Maturity : 10', 'Tenor : 3; Maturity : 10', 'Tenor : 4; Maturity : 10', 'Tenor : 5; Maturity : 10', 'Tenor : 6; Maturity : 10', 'Tenor : 7; Maturity : 10', 'Tenor : 8; Maturity : 10', 'Tenor : 9; Maturity : 10', 'Tenor : 10; Maturity : 10', 'Tenor : 15; Maturity : 10', 'Tenor : 20; Maturity : 10', 'Tenor : 25; Maturity : 10', 'Tenor : 30; Maturity : 10', 'Tenor : 1; Maturity : 15', 'Tenor : 2; Maturity : 15', 'Tenor : 3; Maturity : 15', 'Tenor : 4; Maturity : 15', 'Tenor : 5; Maturity : 15', 'Tenor : 6; Maturity : 15', 'Tenor : 7; Maturity : 15', 'Tenor : 8; Maturity : 15', 'Tenor : 9; Maturity : 15', 'Tenor : 10; Maturity : 15', 'Tenor : 15; Maturity : 15', 'Tenor : 20; Maturity : 15', 'Tenor : 25; Maturity : 15', 'Tenor : 30; Maturity : 15', 'Tenor : 1; Maturity : 20', 'Tenor : 2; Maturity : 20', 'Tenor : 3; Maturity : 20', 'Tenor : 4; Maturity : 20', 'Tenor : 5; Maturity : 20', 'Tenor : 6; Maturity : 20', 'Tenor : 7; Maturity : 20', 'Tenor : 8; Maturity : 20', 'Tenor : 9; Maturity : 20', 'Tenor : 10; Maturity : 20', 'Tenor : 15; Maturity : 20', 'Tenor : 20; Maturity : 20', 'Tenor : 25; Maturity : 20', 'Tenor : 30; Maturity : 20', 'Tenor : 1; Maturity : 25', 'Tenor : 2; Maturity : 25', 'Tenor : 3; Maturity : 25', 'Tenor : 4; Maturity : 25', 'Tenor : 5; Maturity : 25', 'Tenor : 6; Maturity : 25', 'Tenor : 7; Maturity : 25', 'Tenor : 8; Maturity : 25', 'Tenor : 9; Maturity : 25', 'Tenor : 10; Maturity : 25', 'Tenor : 15; Maturity : 25', 'Tenor : 20; Maturity : 25', 'Tenor : 25; Maturity : 25', 'Tenor : 30; Maturity : 25', 'Tenor : 1; Maturity : 30', 'Tenor : 2; Maturity : 30', 'Tenor : 3; Maturity : 30', 'Tenor : 4; Maturity : 30', 'Tenor : 5; Maturity : 30', 'Tenor : 6; Maturity : 30', 'Tenor : 7; Maturity : 30', 'Tenor : 8; Maturity : 30', 'Tenor : 9; Maturity : 30', 'Tenor : 10; Maturity : 30', 'Tenor : 15; Maturity : 30', 'Tenor : 20; Maturity : 30', 'Tenor : 25; Maturity : 30', 'Tenor : 30; Maturity : 30']\n",
      "Warning: using fallback target inference (last two numeric columns).\n",
      "Numeric columns: ['Tenor : 1; Maturity : 0.0833333333333333', 'Tenor : 2; Maturity : 0.0833333333333333', 'Tenor : 3; Maturity : 0.0833333333333333', 'Tenor : 4; Maturity : 0.0833333333333333', 'Tenor : 5; Maturity : 0.0833333333333333', 'Tenor : 6; Maturity : 0.0833333333333333', 'Tenor : 7; Maturity : 0.0833333333333333', 'Tenor : 8; Maturity : 0.0833333333333333', 'Tenor : 9; Maturity : 0.0833333333333333', 'Tenor : 10; Maturity : 0.0833333333333333', 'Tenor : 15; Maturity : 0.0833333333333333', 'Tenor : 20; Maturity : 0.0833333333333333', 'Tenor : 25; Maturity : 0.0833333333333333', 'Tenor : 30; Maturity : 0.0833333333333333', 'Tenor : 1; Maturity : 0.25', 'Tenor : 2; Maturity : 0.25', 'Tenor : 3; Maturity : 0.25', 'Tenor : 4; Maturity : 0.25', 'Tenor : 5; Maturity : 0.25', 'Tenor : 6; Maturity : 0.25', 'Tenor : 7; Maturity : 0.25', 'Tenor : 8; Maturity : 0.25', 'Tenor : 9; Maturity : 0.25', 'Tenor : 10; Maturity : 0.25', 'Tenor : 15; Maturity : 0.25', 'Tenor : 20; Maturity : 0.25', 'Tenor : 25; Maturity : 0.25', 'Tenor : 30; Maturity : 0.25', 'Tenor : 1; Maturity : 0.5', 'Tenor : 2; Maturity : 0.5', 'Tenor : 3; Maturity : 0.5', 'Tenor : 4; Maturity : 0.5', 'Tenor : 5; Maturity : 0.5', 'Tenor : 6; Maturity : 0.5', 'Tenor : 7; Maturity : 0.5', 'Tenor : 8; Maturity : 0.5', 'Tenor : 9; Maturity : 0.5', 'Tenor : 10; Maturity : 0.5', 'Tenor : 15; Maturity : 0.5', 'Tenor : 20; Maturity : 0.5', 'Tenor : 25; Maturity : 0.5', 'Tenor : 30; Maturity : 0.5', 'Tenor : 1; Maturity : 0.75', 'Tenor : 2; Maturity : 0.75', 'Tenor : 3; Maturity : 0.75', 'Tenor : 4; Maturity : 0.75', 'Tenor : 5; Maturity : 0.75', 'Tenor : 6; Maturity : 0.75', 'Tenor : 7; Maturity : 0.75', 'Tenor : 8; Maturity : 0.75', 'Tenor : 9; Maturity : 0.75', 'Tenor : 10; Maturity : 0.75', 'Tenor : 15; Maturity : 0.75', 'Tenor : 20; Maturity : 0.75', 'Tenor : 25; Maturity : 0.75', 'Tenor : 30; Maturity : 0.75', 'Tenor : 1; Maturity : 1', 'Tenor : 2; Maturity : 1', 'Tenor : 3; Maturity : 1', 'Tenor : 4; Maturity : 1', 'Tenor : 5; Maturity : 1', 'Tenor : 6; Maturity : 1', 'Tenor : 7; Maturity : 1', 'Tenor : 8; Maturity : 1', 'Tenor : 9; Maturity : 1', 'Tenor : 10; Maturity : 1', 'Tenor : 15; Maturity : 1', 'Tenor : 20; Maturity : 1', 'Tenor : 25; Maturity : 1', 'Tenor : 30; Maturity : 1', 'Tenor : 1; Maturity : 1.5', 'Tenor : 2; Maturity : 1.5', 'Tenor : 3; Maturity : 1.5', 'Tenor : 4; Maturity : 1.5', 'Tenor : 5; Maturity : 1.5', 'Tenor : 6; Maturity : 1.5', 'Tenor : 7; Maturity : 1.5', 'Tenor : 8; Maturity : 1.5', 'Tenor : 9; Maturity : 1.5', 'Tenor : 10; Maturity : 1.5', 'Tenor : 15; Maturity : 1.5', 'Tenor : 20; Maturity : 1.5', 'Tenor : 25; Maturity : 1.5', 'Tenor : 30; Maturity : 1.5', 'Tenor : 1; Maturity : 2', 'Tenor : 2; Maturity : 2', 'Tenor : 3; Maturity : 2', 'Tenor : 4; Maturity : 2', 'Tenor : 5; Maturity : 2', 'Tenor : 6; Maturity : 2', 'Tenor : 7; Maturity : 2', 'Tenor : 8; Maturity : 2', 'Tenor : 9; Maturity : 2', 'Tenor : 10; Maturity : 2', 'Tenor : 15; Maturity : 2', 'Tenor : 20; Maturity : 2', 'Tenor : 25; Maturity : 2', 'Tenor : 30; Maturity : 2', 'Tenor : 1; Maturity : 3', 'Tenor : 2; Maturity : 3', 'Tenor : 3; Maturity : 3', 'Tenor : 4; Maturity : 3', 'Tenor : 5; Maturity : 3', 'Tenor : 6; Maturity : 3', 'Tenor : 7; Maturity : 3', 'Tenor : 8; Maturity : 3', 'Tenor : 9; Maturity : 3', 'Tenor : 10; Maturity : 3', 'Tenor : 15; Maturity : 3', 'Tenor : 20; Maturity : 3', 'Tenor : 25; Maturity : 3', 'Tenor : 30; Maturity : 3', 'Tenor : 1; Maturity : 4', 'Tenor : 2; Maturity : 4', 'Tenor : 3; Maturity : 4', 'Tenor : 4; Maturity : 4', 'Tenor : 5; Maturity : 4', 'Tenor : 6; Maturity : 4', 'Tenor : 7; Maturity : 4', 'Tenor : 8; Maturity : 4', 'Tenor : 9; Maturity : 4', 'Tenor : 10; Maturity : 4', 'Tenor : 15; Maturity : 4', 'Tenor : 20; Maturity : 4', 'Tenor : 25; Maturity : 4', 'Tenor : 30; Maturity : 4', 'Tenor : 1; Maturity : 5', 'Tenor : 2; Maturity : 5', 'Tenor : 3; Maturity : 5', 'Tenor : 4; Maturity : 5', 'Tenor : 5; Maturity : 5', 'Tenor : 6; Maturity : 5', 'Tenor : 7; Maturity : 5', 'Tenor : 8; Maturity : 5', 'Tenor : 9; Maturity : 5', 'Tenor : 10; Maturity : 5', 'Tenor : 15; Maturity : 5', 'Tenor : 20; Maturity : 5', 'Tenor : 25; Maturity : 5', 'Tenor : 30; Maturity : 5', 'Tenor : 1; Maturity : 7', 'Tenor : 2; Maturity : 7', 'Tenor : 3; Maturity : 7', 'Tenor : 4; Maturity : 7', 'Tenor : 5; Maturity : 7', 'Tenor : 6; Maturity : 7', 'Tenor : 7; Maturity : 7', 'Tenor : 8; Maturity : 7', 'Tenor : 9; Maturity : 7', 'Tenor : 10; Maturity : 7', 'Tenor : 15; Maturity : 7', 'Tenor : 20; Maturity : 7', 'Tenor : 25; Maturity : 7', 'Tenor : 30; Maturity : 7', 'Tenor : 1; Maturity : 10', 'Tenor : 2; Maturity : 10', 'Tenor : 3; Maturity : 10', 'Tenor : 4; Maturity : 10', 'Tenor : 5; Maturity : 10', 'Tenor : 6; Maturity : 10', 'Tenor : 7; Maturity : 10', 'Tenor : 8; Maturity : 10', 'Tenor : 9; Maturity : 10', 'Tenor : 10; Maturity : 10', 'Tenor : 15; Maturity : 10', 'Tenor : 20; Maturity : 10', 'Tenor : 25; Maturity : 10', 'Tenor : 30; Maturity : 10', 'Tenor : 1; Maturity : 15', 'Tenor : 2; Maturity : 15', 'Tenor : 3; Maturity : 15', 'Tenor : 4; Maturity : 15', 'Tenor : 5; Maturity : 15', 'Tenor : 6; Maturity : 15', 'Tenor : 7; Maturity : 15', 'Tenor : 8; Maturity : 15', 'Tenor : 9; Maturity : 15', 'Tenor : 10; Maturity : 15', 'Tenor : 15; Maturity : 15', 'Tenor : 20; Maturity : 15', 'Tenor : 25; Maturity : 15', 'Tenor : 30; Maturity : 15', 'Tenor : 1; Maturity : 20', 'Tenor : 2; Maturity : 20', 'Tenor : 3; Maturity : 20', 'Tenor : 4; Maturity : 20', 'Tenor : 5; Maturity : 20', 'Tenor : 6; Maturity : 20', 'Tenor : 7; Maturity : 20', 'Tenor : 8; Maturity : 20', 'Tenor : 9; Maturity : 20', 'Tenor : 10; Maturity : 20', 'Tenor : 15; Maturity : 20', 'Tenor : 20; Maturity : 20', 'Tenor : 25; Maturity : 20', 'Tenor : 30; Maturity : 20', 'Tenor : 1; Maturity : 25', 'Tenor : 2; Maturity : 25', 'Tenor : 3; Maturity : 25', 'Tenor : 4; Maturity : 25', 'Tenor : 5; Maturity : 25', 'Tenor : 6; Maturity : 25', 'Tenor : 7; Maturity : 25', 'Tenor : 8; Maturity : 25', 'Tenor : 9; Maturity : 25', 'Tenor : 10; Maturity : 25', 'Tenor : 15; Maturity : 25', 'Tenor : 20; Maturity : 25', 'Tenor : 25; Maturity : 25', 'Tenor : 30; Maturity : 25', 'Tenor : 1; Maturity : 30', 'Tenor : 2; Maturity : 30', 'Tenor : 3; Maturity : 30', 'Tenor : 4; Maturity : 30', 'Tenor : 5; Maturity : 30', 'Tenor : 6; Maturity : 30', 'Tenor : 7; Maturity : 30', 'Tenor : 8; Maturity : 30', 'Tenor : 9; Maturity : 30', 'Tenor : 10; Maturity : 30', 'Tenor : 15; Maturity : 30', 'Tenor : 20; Maturity : 30', 'Tenor : 25; Maturity : 30', 'Tenor : 30; Maturity : 30']\n",
      "Selected target columns: ['Tenor : 25; Maturity : 30', 'Tenor : 30; Maturity : 30']\n",
      "Train rows: 688 | Val rows: 147 | Test rows: 148\n"
     ]
    }
   ],
   "source": [
    "train_split_name = pick_train_split(ds)\n",
    "raw_train_df = dataset_to_df(ds[train_split_name]).copy()\n",
    "\n",
    "print(\"Train split:\", train_split_name)\n",
    "print(\"Shape:\", raw_train_df.shape)\n",
    "print(\"Columns:\", list(raw_train_df.columns))\n",
    "\n",
    "# Manual override (set this explicitly if auto-detection is wrong)\n",
    "# Example: TARGET_COLS = [\"target_call\", \"target_put\"]\n",
    "TARGET_COLS = None\n",
    "\n",
    "if TARGET_COLS is None:\n",
    "    TARGET_COLS = infer_target_columns(raw_train_df)\n",
    "\n",
    "print(\"Selected target columns:\", TARGET_COLS)\n",
    "\n",
    "missing = [c for c in TARGET_COLS if c not in raw_train_df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Target columns not found: {missing}\")\n",
    "\n",
    "# 70/15/15 split from the train dataset.\n",
    "train_df, temp_df = train_test_split(raw_train_df, test_size=0.30, random_state=SEED)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.50, random_state=SEED)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Train rows:\", len(train_df), \"| Val rows:\", len(val_df), \"| Test rows:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4b1d57",
   "metadata": {},
   "source": [
    "## 5) Feature Preprocessing\n",
    "\n",
    "- Numerical: median imputation + standard scaling\n",
    "- Categorical: most frequent imputation + one-hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d82c769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric cols: 222 | Categorical cols: 1\n",
      "Processed feature dimension: 672\n"
     ]
    }
   ],
   "source": [
    "def build_preprocessor(X_df: pd.DataFrame):\n",
    "    numeric_cols = [c for c in X_df.columns if pd.api.types.is_numeric_dtype(X_df[c])]\n",
    "    categorical_cols = [c for c in X_df.columns if c not in numeric_cols]\n",
    "\n",
    "    num_pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    except TypeError:\n",
    "        ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "    cat_pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", ohe),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_pipe, numeric_cols),\n",
    "            (\"cat\", cat_pipe, categorical_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "    return pre, numeric_cols, categorical_cols\n",
    "\n",
    "\n",
    "X_train_df = train_df.drop(columns=TARGET_COLS)\n",
    "y_train = train_df[TARGET_COLS].astype(np.float32).to_numpy()\n",
    "\n",
    "X_val_df = val_df.drop(columns=TARGET_COLS)\n",
    "y_val = val_df[TARGET_COLS].astype(np.float32).to_numpy()\n",
    "\n",
    "X_test_df = test_df.drop(columns=TARGET_COLS)\n",
    "y_test = test_df[TARGET_COLS].astype(np.float32).to_numpy()\n",
    "\n",
    "preprocessor, num_cols, cat_cols = build_preprocessor(X_train_df)\n",
    "X_train_np = preprocessor.fit_transform(X_train_df)\n",
    "X_val_np = preprocessor.transform(X_val_df)\n",
    "X_test_np = preprocessor.transform(X_test_df)\n",
    "\n",
    "if hasattr(X_train_np, \"toarray\"):\n",
    "    X_train_np = X_train_np.toarray()\n",
    "if hasattr(X_val_np, \"toarray\"):\n",
    "    X_val_np = X_val_np.toarray()\n",
    "if hasattr(X_test_np, \"toarray\"):\n",
    "    X_test_np = X_test_np.toarray()\n",
    "\n",
    "X_train_np = np.asarray(X_train_np, dtype=np.float32)\n",
    "X_val_np = np.asarray(X_val_np, dtype=np.float32)\n",
    "X_test_np = np.asarray(X_test_np, dtype=np.float32)\n",
    "\n",
    "print(\"Numeric cols:\", len(num_cols), \"| Categorical cols:\", len(cat_cols))\n",
    "print(\"Processed feature dimension:\", X_train_np.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c15a36",
   "metadata": {},
   "source": [
    "## 6) Torch Tensors and Dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5783db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 11 | Val batches: 3 | Test batches: 3\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "X_train_t = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_t = torch.tensor(X_val_np, dtype=torch.float32)\n",
    "y_val_t = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test_t = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "train_ds = torch.utils.data.TensorDataset(X_train_t, y_train_t)\n",
    "val_ds = torch.utils.data.TensorDataset(X_val_t, y_val_t)\n",
    "test_ds = torch.utils.data.TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"Train batches:\", len(train_loader), \"| Val batches:\", len(val_loader), \"| Test batches:\", len(test_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb7fd20",
   "metadata": {},
   "source": [
    "## 7) Hybrid QML Model (Classical Projection + Quantum Layer + Regression Head)\n",
    "\n",
    "This avoids large input width in the quantum layer by projecting features down to a compact quantum input size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cac4f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QMLConfig(n_quantum_inputs=8, n_modes=10, n_photons=3, grouped_features=16, hidden_dim=64, lr=0.001, epochs=25)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class QMLConfig:\n",
    "    n_quantum_inputs: int = 8\n",
    "    n_modes: int = 10\n",
    "    n_photons: int = 3\n",
    "    grouped_features: int = 16\n",
    "    hidden_dim: int = 64\n",
    "    lr: float = 1e-3\n",
    "    epochs: int = 25\n",
    "\n",
    "\n",
    "config = QMLConfig()\n",
    "\n",
    "# Respect simulation constraints in the challenge.\n",
    "config.n_modes = min(max(config.n_modes, config.n_quantum_inputs + 1), 20)\n",
    "config.n_photons = min(config.n_photons, 10)\n",
    "\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b66f51f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridQMLRegressor(\n",
      "  (project): Sequential(\n",
      "    (0): Linear(in_features=672, out_features=8, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (q_layer): QuantumLayer(\n",
      "    (_photon_loss_transform): PhotonLossTransform()\n",
      "    (_detector_transform): DetectorTransform()\n",
      "    (measurement_mapping): Probabilities()\n",
      "  )\n",
      "  (group): LexGrouping()\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Trainable parameters: 6702\n"
     ]
    }
   ],
   "source": [
    "class HybridQMLRegressor(nn.Module):\n",
    "    def __init__(self, input_dim: int, out_dim: int, cfg: QMLConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Linear(input_dim, cfg.n_quantum_inputs),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        builder = CircuitBuilder(n_modes=cfg.n_modes)\n",
    "        builder.add_entangling_layer(trainable=True, name=\"U1\")\n",
    "        builder.add_angle_encoding(modes=list(range(cfg.n_quantum_inputs)), name=\"x\")\n",
    "        builder.add_rotations(trainable=True, name=\"theta\")\n",
    "        builder.add_superpositions(depth=1)\n",
    "\n",
    "        self.q_layer = QuantumLayer(\n",
    "            input_size=cfg.n_quantum_inputs,\n",
    "            builder=builder,\n",
    "            n_photons=cfg.n_photons,\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "\n",
    "        self.group = LexGrouping(self.q_layer.output_size, cfg.grouped_features)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(cfg.grouped_features, cfg.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(cfg.hidden_dim, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.project(x)\n",
    "        q = self.q_layer(z)\n",
    "        g = self.group(q)\n",
    "        return self.head(g)\n",
    "\n",
    "\n",
    "model = HybridQMLRegressor(\n",
    "    input_dim=X_train_np.shape[1],\n",
    "    out_dim=len(TARGET_COLS),\n",
    "    cfg=config,\n",
    ").to(DEVICE)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(model)\n",
    "print(\"Trainable parameters:\", trainable_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae4905c",
   "metadata": {},
   "source": [
    "## 8) Train and Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43fee5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/25 | train_loss=0.091457 | val_loss=0.056957 | val_rmse=0.238656 | val_mae=0.234775\n",
      "Epoch 02/25 | train_loss=0.039011 | val_loss=0.018578 | val_rmse=0.136301 | val_mae=0.132051\n",
      "Epoch 03/25 | train_loss=0.010061 | val_loss=0.002358 | val_rmse=0.048561 | val_mae=0.040610\n",
      "Epoch 04/25 | train_loss=0.001187 | val_loss=0.001010 | val_rmse=0.031776 | val_mae=0.026975\n",
      "Epoch 05/25 | train_loss=0.001181 | val_loss=0.001297 | val_rmse=0.036016 | val_mae=0.030239\n",
      "Epoch 06/25 | train_loss=0.000916 | val_loss=0.000667 | val_rmse=0.025823 | val_mae=0.022166\n",
      "Epoch 07/25 | train_loss=0.000562 | val_loss=0.000528 | val_rmse=0.022968 | val_mae=0.019241\n",
      "Epoch 08/25 | train_loss=0.000542 | val_loss=0.000501 | val_rmse=0.022392 | val_mae=0.018756\n",
      "Epoch 09/25 | train_loss=0.000503 | val_loss=0.000467 | val_rmse=0.021599 | val_mae=0.018247\n",
      "Epoch 10/25 | train_loss=0.000463 | val_loss=0.000439 | val_rmse=0.020951 | val_mae=0.017703\n",
      "Epoch 11/25 | train_loss=0.000431 | val_loss=0.000401 | val_rmse=0.020025 | val_mae=0.016874\n",
      "Epoch 12/25 | train_loss=0.000400 | val_loss=0.000367 | val_rmse=0.019161 | val_mae=0.015875\n",
      "Epoch 13/25 | train_loss=0.000369 | val_loss=0.000345 | val_rmse=0.018570 | val_mae=0.015388\n",
      "Epoch 14/25 | train_loss=0.000344 | val_loss=0.000323 | val_rmse=0.017958 | val_mae=0.014837\n",
      "Epoch 15/25 | train_loss=0.000318 | val_loss=0.000301 | val_rmse=0.017351 | val_mae=0.014256\n",
      "Epoch 16/25 | train_loss=0.000295 | val_loss=0.000280 | val_rmse=0.016729 | val_mae=0.013569\n",
      "Epoch 17/25 | train_loss=0.000272 | val_loss=0.000263 | val_rmse=0.016225 | val_mae=0.013075\n",
      "Epoch 18/25 | train_loss=0.000251 | val_loss=0.000247 | val_rmse=0.015706 | val_mae=0.012631\n",
      "Epoch 19/25 | train_loss=0.000234 | val_loss=0.000230 | val_rmse=0.015173 | val_mae=0.012104\n",
      "Epoch 20/25 | train_loss=0.000219 | val_loss=0.000216 | val_rmse=0.014714 | val_mae=0.011716\n",
      "Epoch 21/25 | train_loss=0.000206 | val_loss=0.000206 | val_rmse=0.014345 | val_mae=0.011344\n",
      "Epoch 22/25 | train_loss=0.000193 | val_loss=0.000195 | val_rmse=0.013957 | val_mae=0.011031\n",
      "Epoch 23/25 | train_loss=0.000184 | val_loss=0.000185 | val_rmse=0.013595 | val_mae=0.010721\n",
      "Epoch 24/25 | train_loss=0.000173 | val_loss=0.000175 | val_rmse=0.013233 | val_mae=0.010422\n",
      "Epoch 25/25 | train_loss=0.000166 | val_loss=0.000166 | val_rmse=0.012884 | val_mae=0.010095\n",
      "Best validation loss: 0.00016600818814374\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            yhat = model(xb)\n",
    "            loss = loss_fn(yhat, yb)\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "            preds.append(yhat.cpu().numpy())\n",
    "            targets.append(yb.cpu().numpy())\n",
    "\n",
    "    preds = np.vstack(preds)\n",
    "    targets = np.vstack(targets)\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    rmse = mean_squared_error(targets, preds) ** 0.5\n",
    "    mae = mean_absolute_error(targets, preds)\n",
    "    return avg_loss, rmse, mae, preds, targets\n",
    "\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "history = []\n",
    "best_val = float(\"inf\")\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, config.epochs + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(xb)\n",
    "        loss = loss_fn(yhat, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running += loss.item() * xb.size(0)\n",
    "\n",
    "    train_loss = running / len(train_loader.dataset)\n",
    "    val_loss, val_rmse, val_mae, _, _ = evaluate(model, val_loader, loss_fn)\n",
    "\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    history.append((epoch, train_loss, val_loss, val_rmse, val_mae))\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d}/{config.epochs} | \"\n",
    "        f\"train_loss={train_loss:.6f} | val_loss={val_loss:.6f} | \"\n",
    "        f\"val_rmse={val_rmse:.6f} | val_mae={val_mae:.6f}\"\n",
    "    )\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "print(\"Best validation loss:\", best_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a54dd",
   "metadata": {},
   "source": [
    "## 9) Validation and Test Diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b78964b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3e4d9aeb-eade-4894-be71-fb7e51af4ace\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_rmse</th>\n",
       "      <th>val_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>0.011344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.013957</td>\n",
       "      <td>0.011031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.013595</td>\n",
       "      <td>0.010721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>0.010422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.012884</td>\n",
       "      <td>0.010095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e4d9aeb-eade-4894-be71-fb7e51af4ace')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3e4d9aeb-eade-4894-be71-fb7e51af4ace button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3e4d9aeb-eade-4894-be71-fb7e51af4ace');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss  val_rmse   val_mae\n",
       "20     21    0.000206  0.000206  0.014345  0.011344\n",
       "21     22    0.000193  0.000195  0.013957  0.011031\n",
       "22     23    0.000184  0.000185  0.013595  0.010721\n",
       "23     24    0.000173  0.000175  0.013233  0.010422\n",
       "24     25    0.000166  0.000166  0.012884  0.010095"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAGJCAYAAABo5eDAAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUXhJREFUeJzt3Xl8U2Xe///3SdqmC22hLbQUCy1YEAGLspSCikq1oKKACyIzAjoyjoBL1RH8iSzqcI8rLig3zlcdHQHFW1BRUURxARTZFBUQsSwjtGzSQkvXnN8fIaGhBZpuWfp6Ph55JDm5rpPPSczMuxfXuY5hmqYpAAAAIEBZvF0AAAAA0JAIvAAAAAhoBF4AAAAENAIvAAAAAhqBFwAAAAGNwAsAAICARuAFAABAQCPwAgAAIKAReAEAABDQCLwAUM9Gjx6t5OTkWvWdOnWqDMOo34IAoIkj8AJoMgzDqNFt+fLl3i7Vq5YvX65hw4YpISFBISEhatWqlQYPHqx33nnH26UBQK0Ypmma3i4CABrDf/7zH7fnr732mpYuXarXX3/dbfull16q+Pj4Wr9PWVmZ7Ha7bDabx33Ly8tVXl6u0NDQWr9/XUyZMkXTp09XamqqRowYoXbt2unAgQP68MMPtXz5cr3xxhu68cYbvVIbANQWgRdAkzV+/HjNmjVLp/ufwaKiIoWHhzdSVd7z9ttv67rrrtO1116ruXPnKjg42O31jz/+WGVlZbryyivr/F5N5TMF4BuY0gAAlVx00UXq2rWr1q5dqwsvvFDh4eF64IEHJEnvvvuurrjiCiUmJspms6lDhw56+OGHVVFR4baPE+fwbt++XYZh6IknntCcOXPUoUMH2Ww29erVS999951b3+rm8BqGofHjx2vRokXq2rWrbDabunTpoiVLllSpf/ny5erZs6dCQ0PVoUMH/e///m+N5wVPnjxZMTExevnll6uEXUnKyspyhd1XX31VhmFo+/btVd7/xGkhJ/tMr7zySrVv377aWjIyMtSzZ0+3bf/5z3/Uo0cPhYWFKSYmRjfccIN27drl1mbr1q265pprlJCQoNDQUJ1xxhm64YYblJ+ff9rjBxC4grxdAAD4mgMHDmjQoEG64YYb9Kc//ck1veHVV19Vs2bNlJ2drWbNmumzzz7TQw89pIKCAj3++OOn3e/cuXN1+PBh/fWvf5VhGHrsscc0bNgw/fbbb9UGzMq+/vprvfPOO7r99tsVGRmpZ599Vtdcc4127typ2NhYSdL69es1cOBAtW7dWtOmTVNFRYWmT5+uli1bnra2rVu3avPmzbr55psVGRlZg0/JM9V9pj169NBNN92k7777Tr169XK13bFjh7755hu3z/TRRx/V5MmTdf311+svf/mL9u3bp+eee04XXnih1q9fr+bNm6u0tFRZWVkqKSnRhAkTlJCQoN9//12LFy/WoUOHFB0dXe/HBcBPmADQRI0bN8488X8G+/fvb0oyZ8+eXaV9UVFRlW1//etfzfDwcLO4uNi1bdSoUWa7du1cz3NyckxJZmxsrHnw4EHX9nfffdeUZL7//vuubVOmTKlSkyQzJCTE/PXXX13bvv/+e1OS+dxzz7m2DR482AwPDzd///1317atW7eaQUFBVfZ5ImctTz/99CnbOb3yyiumJDMnJ8dt++eff25KMj///HPXtpN9pvn5+abNZjPvuecet+2PPfaYaRiGuWPHDtM0TXP79u2m1Wo1H330Ubd2GzduNIOCglzb169fb0oyFyxYUKNjANB0MKUBAE5gs9k0ZsyYKtvDwsJcjw8fPqz9+/frggsuUFFRkTZv3nza/Q4fPlwtWrRwPb/gggskSb/99ttp+2ZmZqpDhw6u5+ecc46ioqJcfSsqKvTpp59qyJAhSkxMdLU788wzNWjQoNPuv6CgQJIaZHRXqv4zjYqK0qBBg/TWW2+5zaN+88031adPH7Vt21aS9M4778hut+v666/X/v37XbeEhASlpqbq888/lyTXCO7HH3+soqKiBjkOAP6JwAsAJ2jTpo1CQkKqbP/pp580dOhQRUdHKyoqSi1bttSf/vQnSarRHFFngHNyht8//vjD477O/s6+e/fu1dGjR3XmmWdWaVfdthNFRUVJcgT5hnCyz3T48OHatWuXVq1aJUnatm2b1q5dq+HDh7vabN26VaZpKjU1VS1btnS7bdq0SXv37pUkpaSkKDs7W//6178UFxenrKwszZo1i/m7AJjDCwAnqjyS63To0CH1799fUVFRmj59ujp06KDQ0FCtW7dO999/v+x2+2n3a7Vaq91u1mCxnLr0rYmzzjpLkrRx48YatT/ZSXAnnsDnVN1nKkmDBw9WeHi43nrrLfXt21dvvfWWLBaLrrvuOlcbu90uwzD00UcfVfs5NGvWzPX4ySef1OjRo/Xuu+/qk08+0R133KEZM2bom2++0RlnnFGjYwMQeAi8AFADy5cv14EDB/TOO+/owgsvdG3PycnxYlXHtWrVSqGhofr111+rvFbdthN17NhRnTp10rvvvqtnnnnGLURWxzk6fejQIbftO3bsqHnRkiIiInTllVdqwYIFeuqpp/Tmm2/qggsucJuW0aFDB5mmqZSUFHXs2PG0++zWrZu6deumBx98UCtXrlS/fv00e/ZsPfLIIx7VBiBwMKUBAGrAObJYeUS1tLRUL7zwgrdKcmO1WpWZmalFixZp9+7dru2//vqrPvrooxrtY9q0aTpw4ID+8pe/qLy8vMrrn3zyiRYvXixJrvnEX375pev1iooKzZkzx+Pahw8frt27d+tf//qXvv/+e7fpDJI0bNgwWa1WTZs2rcqItmmaOnDggCTHPOQT6+7WrZssFotKSko8rgtA4GCEFwBqoG/fvmrRooVGjRqlO+64Q4Zh6PXXX6+3KQX1YerUqfrkk0/Ur18//e1vf1NFRYWef/55de3aVRs2bDht/+HDh2vjxo169NFHtX79ercrrS1ZskTLli3T3LlzJUldunRRnz59NGnSJB08eFAxMTGaP39+tUH5dC6//HJFRkbq3nvvldVq1TXXXOP2eocOHfTII49o0qRJ2r59u4YMGaLIyEjl5ORo4cKFGjt2rO6991599tlnGj9+vK677jp17NhR5eXlev3116vdJ4CmhcALADUQGxurxYsX65577tGDDz6oFi1a6E9/+pMGDBigrKwsb5cnSerRo4c++ugj3XvvvZo8ebKSkpI0ffp0bdq0qUarSEjSI488oksuuUTPPvusXnzxRR08eFAtWrRQnz599O677+qqq65ytX3jjTf017/+Vf/zP/+j5s2b65ZbbtHFF1+sSy+91KO6Q0NDddVVV+mNN95QZmamWrVqVaXNxIkT1bFjRz399NOaNm2aJCkpKUmXXXaZq6a0tDRlZWXp/fff1++//67w8HClpaXpo48+Up8+fTyqCUBg4dLCABDghgwZop9++klbt271dikA4BXM4QWAAHL06FG351u3btWHH36oiy66yDsFAYAPYIQXAAJI69atNXr0aLVv3147duzQiy++qJKSEq1fv16pqaneLg8AvII5vAAQQAYOHKh58+YpNzdXNptNGRkZ+sc//kHYBdCkMcILAACAgMYcXgAAAAQ0Ai8AAAACGnN4q2G327V7925FRkae9HrxAAAA8B7TNHX48GElJibKYjn1GC6Btxq7d+9WUlKSt8sAAADAaezatUtnnHHGKdsQeKsRGRkpyfEBRkVFebkaAAAAnKigoEBJSUmu3HYqBN5qOKcxREVFEXgBAAB8WE2mn3LSGgAAAAIagRcAAAABjcALAACAgMYcXgAAEHBM01R5ebkqKiq8XQpqyWq1KigoqF6WiCXwAgCAgFJaWqo9e/aoqKjI26WgjsLDw9W6dWuFhITUaT8EXgAAEDDsdrtycnJktVqVmJiokJAQLiLlh0zTVGlpqfbt26ecnBylpqae9uISp0LgBQAAAaO0tFR2u11JSUkKDw/3djmog7CwMAUHB2vHjh0qLS1VaGhorffFSWsAACDg1GU0EL6jvr5H/msAAABAQCPw+oC1O/7QgjW7VFBc5u1SAAAAAg6B1wfcMW+97nv7B/2Se9jbpQAAgACQnJysmTNn1su+li9fLsMwdOjQoXrZnzcQeH1AcpxjUn3O/kIvVwIAALzloosu0l133VUv+/ruu+80duzYetlXICDw+oDk2AhJ0vYDBF4AAFA958U0aqJly5asUlEJgdcHpMQ5Ai8jvAAA1D/TNFVUWt7oN9M0a1zj6NGj9cUXX+iZZ56RYRgyDEOvvvqqDMPQRx99pB49eshms+nrr7/Wtm3bdPXVVys+Pl7NmjVTr1699Omnn7rt78QpDYZh6F//+peGDh2q8PBwpaam6r333qv1Z/p///d/6tKli2w2m5KTk/Xkk0+6vf7CCy8oNTVVoaGhio+P17XXXut67e2331a3bt0UFham2NhYZWZmqrCwYTMQ6/D6gOOBlyvCAABQ346WVejshz5u9Pf9eXqWwkNqFrWeeeYZ/fLLL+rataumT58uSfrpp58kSRMnTtQTTzyh9u3bq0WLFtq1a5cuv/xyPfroo7LZbHrttdc0ePBgbdmyRW3btj3pe0ybNk2PPfaYHn/8cT333HMaOXKkduzYoZiYGI+Oa+3atbr++us1depUDR8+XCtXrtTtt9+u2NhYjR49WmvWrNEdd9yh119/XX379tXBgwf11VdfSZL27NmjESNG6LHHHtPQoUN1+PBhffXVVx79cVAbBF4f4Ay82/cXyjRNrggDAEATEx0drZCQEIWHhyshIUGStHnzZknS9OnTdemll7raxsTEKC0tzfX84Ycf1sKFC/Xee+9p/PjxJ32P0aNHa8SIEZKkf/zjH3r22We1evVqDRw40KNan3rqKQ0YMECTJ0+WJHXs2FE///yzHn/8cY0ePVo7d+5URESErrzySkVGRqpdu3Y699xzJTkCb3l5uYYNG6Z27dpJkrp16+bR+9cGgdcHJMWEy2oxdLSsQnkFJUqIrv2VRAAAgLuwYKt+np7llfetDz179nR7fuTIEU2dOlUffPCBK0AePXpUO3fuPOV+zjnnHNfjiIgIRUVFae/evR7Xs2nTJl199dVu2/r166eZM2eqoqJCl156qdq1a6f27dtr4MCBGjhwoGsqRVpamgYMGKBu3bopKytLl112ma699lq1aNHC4zo8wRxeHxBsteiMFmGSmMcLAEB9MwxD4SFBjX6rr3+xjYiIcHt+7733auHChfrHP/6hr776Shs2bFC3bt1UWlp6yv0EBwdX+Vzsdnu91FhZZGSk1q1bp3nz5ql169Z66KGHlJaWpkOHDslqtWrp0qX66KOPdPbZZ+u5555Tp06dlJOTU+91VEbg9RGcuAYAQNMWEhKiioqK07ZbsWKFRo8eraFDh6pbt25KSEjQ9u3bG77AYzp37qwVK1ZUqaljx46yWh2j2kFBQcrMzNRjjz2mH374Qdu3b9dnn30myRG0+/Xrp2nTpmn9+vUKCQnRwoULG7RmpjT4CMfSZPtYmgwAgCYqOTlZ3377rbZv365mzZqddPQ1NTVV77zzjgYPHizDMDR58uQGGak9mXvuuUe9evXSww8/rOHDh2vVqlV6/vnn9cILL0iSFi9erN9++00XXnihWrRooQ8//FB2u12dOnXSt99+q2XLlumyyy5Tq1at9O2332rfvn3q3Llzg9bMCK+PYIQXAICm7d5775XVatXZZ5+tli1bnnRO7lNPPaUWLVqob9++Gjx4sLKysnTeeec1Wp3nnXee3nrrLc2fP19du3bVQw89pOnTp2v06NGSpObNm+udd97RJZdcos6dO2v27NmaN2+eunTpoqioKH355Ze6/PLL1bFjRz344IN68sknNWjQoAat2TAbeh0IP1RQUKDo6Gjl5+crKiqqUd7zy1/26aaXV+vMVs30aXb/RnlPAAACTXFxsXJycpSSkqLQUE4C93en+j49yWuM8PoI5wjvzgNFqrDzNwgAAEB9IfD6iMTmYQqxWlRaYdfuQ0e9XQ4AAGgibrvtNjVr1qza22233ebt8uoFJ635CKvFUNvYcP2694hy9hcqKYbrXwMAgIY3ffp03XvvvdW+1lhTOxsagdeHJMdG6Ne9R7T9QKEuVEtvlwMAAJqAVq1aqVWrVt4uo0ExpcGHtG/pmMf72z5WagAAAKgvBF4f4liLV6zFCwAAUI8IvD7EuVLDdtbiBQAAqDcEXh/iDLy7/jiqsorGu2IKAABAICPw+pD4KJvCgq2qsJvadbDI2+UAAAAEBAKvDzEMQ8lcYhgAANRCcnKyZs6cWaO2hmFo0aJFDVqPLyHw+piUOMf6uwReAACA+kHg9TGs1AAAAFC/CLw+JoUpDQAA1C/TlEoLG/9mmjUucc6cOUpMTJTd7n7S+tVXX62bb75Z27Zt09VXX634+Hg1a9ZMvXr10qefflpvH9HGjRt1ySWXKCwsTLGxsRo7dqyOHDnien358uXq3bu3IiIi1Lx5c/Xr1087duyQJH3//fe6+OKLFRkZqaioKPXo0UNr1qypt9rqA1da8zHHlybjpDUAAOpFWZH0j8TGf98HdkshETVqet1112nChAn6/PPPNWDAAEnSwYMHtWTJEn344Yc6cuSILr/8cj366KOy2Wx67bXXNHjwYG3ZskVt27atU5mFhYXKyspSRkaGvvvuO+3du1d/+ctfNH78eL366qsqLy/XkCFDdOutt2revHkqLS3V6tWrZRiGJGnkyJE699xz9eKLL8pqtWrDhg0KDg6uU031jcDrY5yBd3f+URWXVSg02OrligAAQENr0aKFBg0apLlz57oC79tvv624uDhdfPHFslgsSktLc7V/+OGHtXDhQr333nsaP358nd577ty5Ki4u1muvvaaICEcOef755zV48GD985//VHBwsPLz83XllVeqQ4cOkqTOnTu7+u/cuVP33XefzjrrLElSampqneppCAReHxMTEaLI0CAdLi7XjgNF6pQQ6e2SAADwb8HhjtFWb7yvB0aOHKlbb71VL7zwgmw2m9544w3dcMMNslgsOnLkiKZOnaoPPvhAe/bsUXl5uY4ePaqdO3fWucxNmzYpLS3NFXYlqV+/frLb7dqyZYsuvPBCjR49WllZWbr00kuVmZmp66+/Xq1bt5YkZWdn6y9/+Ytef/11ZWZm6rrrrnMFY1/BHF4fYxgG83gBAKhPhuGYWtDYt2P/5F9TgwcPlmma+uCDD7Rr1y599dVXGjlypCTp3nvv1cKFC/WPf/xDX331lTZs2KBu3bqptLS0IT6xKl555RWtWrVKffv21ZtvvqmOHTvqm2++kSRNnTpVP/30k6644gp99tlnOvvss7Vw4cJGqaumCLw+iMALAEDTExoaqmHDhumNN97QvHnz1KlTJ5133nmSpBUrVmj06NEaOnSounXrpoSEBG3fvr1e3rdz5876/vvvVVh4PHesWLFCFotFnTp1cm0799xzNWnSJK1cuVJdu3bV3LlzXa917NhRd999tz755BMNGzZMr7zySr3UVl8IvD7ItTQZgRcAgCZl5MiR+uCDD/Tyyy+7Rnclx7zYd955Rxs2bND333+vG2+8scqKDnV5z9DQUI0aNUo//vijPv/8c02YMEF//vOfFR8fr5ycHE2aNEmrVq3Sjh079Mknn2jr1q3q3Lmzjh49qvHjx2v58uXasWOHVqxYoe+++85tjq8vYA6vD3KN8LIWLwAATcoll1yimJgYbdmyRTfeeKNr+1NPPaWbb75Zffv2VVxcnO6//34VFBTUy3uGh4fr448/1p133qlevXopPDxc11xzjZ566inX65s3b9a///1vHThwQK1bt9a4ceP017/+VeXl5Tpw4IBuuukm5eXlKS4uTsOGDdO0adPqpbb6YpimB4vENYBZs2bp8ccfV25urtLS0vTcc8+pd+/eJ22/YMECTZ48Wdu3b1dqaqr++c9/6vLLL3e9fuTIEU2cOFGLFi3SgQMHlJKSojvuuEO33XZbjWsqKChQdHS08vPzFRUVVafjq43vdx3S1bNWqGWkTd/9f5mN/v4AAPir4uJi5eTkKCUlRaGhod4uB3V0qu/Tk7zm1SkNb775prKzszVlyhStW7dOaWlpysrK0t69e6ttv3LlSo0YMUK33HKL1q9fryFDhmjIkCH68ccfXW2ys7O1ZMkS/ec//9GmTZt01113afz48Xrvvfca67DqLPnYCO++wyU6UlLu5WoAAAD8m1cD71NPPaVbb71VY8aM0dlnn63Zs2crPDxcL7/8crXtn3nmGQ0cOFD33XefOnfurIcffljnnXeenn/+eVeblStXatSoUbrooouUnJyssWPHKi0tTatXr26sw6qz6LBgxUaESGIeLwAA8Mwbb7yhZs2aVXvr0qWLt8vzCq/N4S0tLdXatWs1adIk1zaLxaLMzEytWrWq2j6rVq1Sdna227asrCwtWrTI9bxv37567733dPPNNysxMVHLly/XL7/8oqeffvqktZSUlKikpMT1vL7mxNRFclyEDhSWKmd/obq2ifZ2OQAAwE9cddVVSk9Pr/Y1X7sCWmPxWuDdv3+/KioqFB8f77Y9Pj5emzdvrrZPbm5ute1zc3Ndz5977jmNHTtWZ5xxhoKCgmSxWPTSSy/pwgsvPGktM2bM8LnJ1cmxEVq74w9GeAEAgEciIyMVGcmFqyoLuGXJnnvuOX3zzTd67733tHbtWj355JMaN26cPv3005P2mTRpkvLz8123Xbt2NWLF1WvfkpUaAACoLS+fk496Ul/fo9dGeOPi4mS1WpWXl+e2PS8vTwkJCdX2SUhIOGX7o0eP6oEHHtDChQt1xRVXSJLOOeccbdiwQU888YQyM6tf8cBms8lms9X1kOqVcy1eLj4BAEDNOf/JvqioSGFhYV6uBnVVVFQkqe5TMbwWeENCQtSjRw8tW7ZMQ4YMkSTZ7XYtW7ZM48ePr7ZPRkaGli1bprvuusu1benSpcrIyJAklZWVqaysTBaL+8C11Wqtt8WZG0tynOP620xpAACg5qxWq5o3b+5a8Sk8PFyGh5f4hfeZpqmioiLt3btXzZs3l9VqrdP+vHrhiezsbI0aNUo9e/ZU7969NXPmTBUWFmrMmDGSpJtuuklt2rTRjBkzJEl33nmn+vfvryeffFJXXHGF5s+frzVr1mjOnDmSpKioKPXv31/33XefwsLC1K5dO33xxRd67bXXXIsn+wvnCO8fRWU6VFSq5uEhXq4IAAD/4PyX35Mtcwr/0bx585P+y78nvBp4hw8frn379umhhx5Sbm6uunfvriVLlrhOTNu5c6fbaG3fvn01d+5cPfjgg3rggQeUmpqqRYsWqWvXrq428+fP16RJkzRy5EgdPHhQ7dq106OPPurRhSd8QYQtSPFRNuUVlChnf6HObUvgBQCgJgzDUOvWrdWqVSuVlZV5uxzUUnBwcJ1Hdp28fqU1X+TtK6053TBnlb757aCeHp6moeee4bU6AAAAfI3fXGkNp5Zy7IprOfuYxwsAAFBbBF4f5lqp4UCRlysBAADwXwReH+Yc4WWlBgAAgNoj8Pow15SG/YUsoA0AAFBLBF4flhQTLsOQjpSUa/+RUm+XAwAA4JcIvD4sNNiqNs0dV4nhimsAAAC1Q+D1cczjBQAAqBsCr49zzeM9QOAFAACoDQKvj3MtTcZavAAAALVC4PVxrikNjPACAADUCoHXx1UOvHY7S5MBAAB4isDr485oEaYgi6HiMrtyC4q9XQ4AAIDfIfD6uCCrRW1jwiWxUgMAAEBtEHj9QPKxaQ2/EXgBAAA8RuD1A86VGhjhBQAA8ByB1w+ktGSlBgAAgNoi8PqBlFimNAAAANQWgdcPJMc5TlrbdbBI5RV2L1cDAADgXwi8fiAxOkwhQRaVVZjafYilyQAAADxB4PUDFouh5FjHKO9v+494uRoAAAD/QuD1E64rrjGPFwAAwCMEXj/hXIs3h8ALAADgEQKvn3Cu1JBzoMjLlQAAAPgXAq+fYEoDAABA7RB4/YQz8P73jyKVlrM0GQAAQE0ReP1Ey0ibIkKsspvSzoNMawAAAKgpAq+fMAzDdeIa0xoAAABqjsDrR1ipAQAAwHMEXj/S3hl4DxB4AQAAaorA60eSnUuT7SPwAgAA1BSB14+45vAywgsAAFBjBF4/4pzSsCe/WEdLK7xcDQAAgH8g8PqRFhEhig4LlsQoLwAAQE0ReP0MS5MBAAB4hsDrZ1ipAQAAwDMEXj/DSg0AAACeIfD6mZSWrNQAAADgCQKvn0lxjvDuL/JyJQAAAP6BwOtnkuPCJUn7j5TocHGZl6sBAADwfQRePxMZGqy4ZjZJ0nZGeQEAAE6LwOuHUo6N8v62/4iXKwEAAPB9BF4/5FypgRFeAACA0yPw+iFWagAAAKg5Aq8fcq7U8BtXWwMAADgtAq8fco3wEngBAABOi8Drh9rFOAJv/tEy/VFY6uVqAAAAfBuB1w+FhVjVOjpUEtMaAAAATofA66dS4pjWAAAAUBMEXj+VHOe8xDCBFwAA4FQIvH7KuVJDDkuTAQAAnJLXA++sWbOUnJys0NBQpaena/Xq1adsv2DBAp111lkKDQ1Vt27d9OGHH1Zps2nTJl111VWKjo5WRESEevXqpZ07dzbUIXgFUxoAAABqxquB980331R2dramTJmidevWKS0tTVlZWdq7d2+17VeuXKkRI0bolltu0fr16zVkyBANGTJEP/74o6vNtm3bdP755+uss87S8uXL9cMPP2jy5MkKDQ1trMNqFJWnNJim6eVqAAAAfJdhejEtpaenq1evXnr++eclSXa7XUlJSZowYYImTpxYpf3w4cNVWFioxYsXu7b16dNH3bt31+zZsyVJN9xwg4KDg/X666/Xuq6CggJFR0crPz9fUVFRtd5PQyott+usyR/JbkqrHxigVlGBFegBAABOxZO85rUR3tLSUq1du1aZmZnHi7FYlJmZqVWrVlXbZ9WqVW7tJSkrK8vV3m6364MPPlDHjh2VlZWlVq1aKT09XYsWLTplLSUlJSooKHC7+bqQIIvOaBEuiRPXAAAATsVrgXf//v2qqKhQfHy82/b4+Hjl5uZW2yc3N/eU7ffu3asjR47of/7nfzRw4EB98sknGjp0qIYNG6YvvvjipLXMmDFD0dHRrltSUlIdj65xsFIDAADA6Xn9pLX6ZLfbJUlXX3217r77bnXv3l0TJ07UlVde6ZryUJ1JkyYpPz/fddu1a1djlVwn7eNYqQEAAOB0grz1xnFxcbJarcrLy3PbnpeXp4SEhGr7JCQknLJ9XFycgoKCdPbZZ7u16dy5s77++uuT1mKz2WSz2WpzGF6VHHtsSsM+Ai8AAMDJeG2ENyQkRD169NCyZctc2+x2u5YtW6aMjIxq+2RkZLi1l6SlS5e62oeEhKhXr17asmWLW5tffvlF7dq1q+cj8L6Uls0kSdsZ4QUAADgpr43wSlJ2drZGjRqlnj17qnfv3po5c6YKCws1ZswYSdJNN92kNm3aaMaMGZKkO++8U/3799eTTz6pK664QvPnz9eaNWs0Z84c1z7vu+8+DR8+XBdeeKEuvvhiLVmyRO+//76WL1/ujUNsUM6LT2w/UCS73ZTFYni5IgAAAN/j1cA7fPhw7du3Tw899JByc3PVvXt3LVmyxHVi2s6dO2WxHB+E7tu3r+bOnasHH3xQDzzwgFJTU7Vo0SJ17drV1Wbo0KGaPXu2ZsyYoTvuuEOdOnXS//3f/+n8889v9ONraInNQxVsNVRabtfu/KOuVRsAAABwnFfX4fVV/rAOr9OAJ5dr275C/eeWdJ2fGuftcgAAABqFX6zDi/qRwkoNAAAAp0Tg9TbTlNa9Li3Olo7+4XH35GPzeFmpAQAAoHoEXm8zDOmrJ6Q1/0/avcHj7iktnSeuEXgBAACqQ+D1Ba27O+73bPC4q3OlBq62BgAAUD0Cry9I7O64r8MI766DRSqvsNdfTQAAAAGCwOsL6jDCGx8ZqtBgi8rtpv77x9F6LQsAACAQEHh9Qes0x/0f2z0+cc1iMY6fuMa0BgAAgCoIvL4gPEZqfuzSx3u+97i7a2kyAi8AAEAVBF5fUYd5vMlxrNQAAABwMgReX8FKDQAAAA2CwOsr6mGlBgIvAABAVQReX+Ec4f0jRzp6yKOuzpPWfj90VMVlFfVbFwAAgJ8j8PqK8BipeVvHYw9PXItrFqJIW5BM07EeLwAAAI4j8PqSxHMd9x7O4zUMw3XiGtMaAAAA3BF4fYlzWsPu9R53JfACAABUj8DrS+py4hpLkwEAAFSLwOtL6nDiWkpcuCRGeAEAAE5E4PUldThxjcsLAwAAVI/A62tqeQEK55SGvIISFZWW129NAAAAfozA62tqOY+3eXiIWoQHS5K272dpMgAAACcCr6+pyyWGWakBAACgCgKvr3GuxXvwN6k436OuyazUAAAAUAWB19eEx0jRtTtxLeXYiWu/7SPwAgAAOBF4fVFimuPew3m8KS0Z4QUAADgRgdcX1XIer3Npsu3M4QUAAHAh8PqiWq7U4JzDe6CwVPlHy+q3JgAAAD/lUeB97LHHdPToUdfzFStWqKSkxPX88OHDuv322+uvuqaqtfPEtW0enbjWzBakVpE2SYzyAgAAOHkUeCdNmqTDhw+7ng8aNEi///6763lRUZH+93//t/6qa6oiYiuduPaDR11ZqQEAAMCdR4HXNM1TPkc9cp24tt6jbu3jWKkBAACgMubw+qranrjGCC8AAIAbAq+vqu2Ja7FcbQ0AAKCyIE87/Otf/1KzZs0kSeXl5Xr11VcVFxcnSW7ze1FHJ564Fhpdo27tWx4PvKZpyjCMhqoQAADAL3gUeNu2bauXXnrJ9TwhIUGvv/56lTaoBxGxUnSSlL/LceJaygU16tY2JlyGIR0uLtfBwlLFNrM1cKEAAAC+zaPAu3379gYqA9VqnXYs8G6oceANDbYqMTpMvx86qpz9hQReAADQ5DGH15fVch5vShzzeAEAAJw8CryrVq3S4sWL3ba99tprSklJUatWrTR27Fi3C1GgjpzzeD1eqSFcEis1AAAASB4G3unTp+unn35yPd+4caNuueUWZWZmauLEiXr//fc1Y8aMei+yyXKO8B74VSouqHG3lDjHSYWM8AIAAHgYeDds2KABAwa4ns+fP1/p6el66aWXlJ2drWeffVZvvfVWvRfZZEXESVFnOB7n1vyKaynHRnhz9hc1RFUAAAB+xaPA+8cffyg+Pt71/IsvvtCgQYNcz3v16qVdu3bVX3Wo1Txe51q8248tTQYAANCUeRR44+PjlZOTI0kqLS3VunXr1KdPH9frhw8fVnBwcP1W2NTV4oprSTHhsloMHS2rUF4Bc6oBAEDT5lHgvfzyyzVx4kR99dVXmjRpksLDw3XBBceXy/rhhx/UoUOHei+ySUs8duKaByO8wVaLklqESWIeLwAAgEeB9+GHH1ZQUJD69++vl156SXPmzFFISIjr9ZdfflmXXXZZvRfZpLlOXNvq4YlrLE0GAAAgeXjhibi4OH355ZfKz89Xs2bNZLVa3V5fsGCBIiMj67XAJs954lrBfx0nriWfX6NuyXER0pZ9LE0GAACaPI8C780331yjdi+//HKtisFJJHZ3BN7dG2oceBnhBQAAcPAo8L766qtq166dzj33XM7+b0ytu0ubF3t04hqBFwAAwMGjwPu3v/1N8+bNU05OjsaMGaM//elPiomJaaja4FSHpcl2HihShd2U1WLUf10AAAB+wKOT1mbNmqU9e/bo73//u95//30lJSXp+uuv18cff8yIb0NyLk124Fep5HCNuiQ2D1OI1aLSCrt2HzracLUBAAD4OI8CryTZbDaNGDFCS5cu1c8//6wuXbro9ttvV3Jyso4cOdIQNaJZSymqjSRT2lOzK65ZLYbaxTqvuMa0BgAA0HR5HHjdOlssMgxDpmmqoqKivmpCdWpxAYrkY/N4WakBAAA0ZR4H3pKSEs2bN0+XXnqpOnbsqI0bN+r555/Xzp071axZs4aoEVKt5vG2PxZ4f9tH4AUAAE2XRyet3X777Zo/f76SkpJ08803a968eYqLi2uo2lAZI7wAAAC14tEI7+zZsxUVFaX27dvriy++0NixYzVs2LAqN0/NmjVLycnJCg0NVXp6ulavXn3K9gsWLNBZZ52l0NBQdevWTR9++OFJ2952220yDEMzZ870uC6f4hzh3b+1xieuOVdq2M4cXgAA0IR5FHhvuukmXXzxxWrevLmio6NPevPEm2++qezsbE2ZMkXr1q1TWlqasrKytHfv3mrbr1y5UiNGjNAtt9yi9evXa8iQIRoyZIh+/PHHKm0XLlyob775RomJiR7V5JOatZIiEyWZUu7GGnVp39IReHf9cVRlFfYGLA4AAMB3GaaX1xNLT09Xr1699Pzzz0uS7Ha7kpKSNGHCBE2cOLFK++HDh6uwsFCLFy92bevTp4+6d++u2bNnu7b9/vvvSk9P18cff6wrrrhCd911l+66664a1VRQUKDo6Gjl5+crKiqqbgdYn+aNkLZ8KGXNkDJuP21z0zTVZcrHKiqt0Gf39Ff7lsyxBgAAgcGTvFanVRrqqrS0VGvXrlVmZqZrm8ViUWZmplatWlVtn1WrVrm1l6SsrCy39na7XX/+85913333qUuXLqeto6SkRAUFBW43n5R4ruN+9/oaNTcMQ+1iueIaAABo2rwaePfv36+KigrFx8e7bY+Pj1dubm61fXJzc0/b/p///KeCgoJ0xx131KiOGTNmuE3JSEpK8vBIGkktTlxrzyWGAQBAE+fVwNsQ1q5dq2eeeUavvvqqDKNml9OdNGmS8vPzXbddu3Y1cJW1VJsT1+IcF59gpQYAANBUeTXwxsXFyWq1Ki8vz217Xl6eEhISqu2TkJBwyvZfffWV9u7dq7Zt2yooKEhBQUHasWOH7rnnHiUnJ1e7T5vNpqioKLebT6rFiWspcY55u7/kchU8AADQNHk18IaEhKhHjx5atmyZa5vdbteyZcuUkZFRbZ+MjAy39pK0dOlSV/s///nP+uGHH7RhwwbXLTExUffdd58+/vjjhjuYxuLhBSh6tmshSdqw65CKSssbpiYAAAAf5tGFJxpCdna2Ro0apZ49e6p3796aOXOmCgsLNWbMGEmOpdDatGmjGTNmSJLuvPNO9e/fX08++aSuuOIKzZ8/X2vWrNGcOXMkSbGxsYqNjXV7j+DgYCUkJKhTp06Ne3ANoXV3x0oNNZzH2y42XG2ah+n3Q0f13fY/1L9jywYtDwAAwNd4fQ7v8OHD9cQTT+ihhx5S9+7dtWHDBi1ZssR1YtrOnTu1Z88eV/u+fftq7ty5mjNnjtLS0vT2229r0aJF6tq1q7cOoXF5OMJrGIb6nen4A2DFr/sbpiYAAAAf5vV1eH2Rz67DK0mH86QnO0oypEn/lWynX1v33Q2/6875G9QlMUof3HFBw9cIAADQwPxmHV7UQmS8FNlanpy41rdDnCTpp90FOlhY2oDFAQAA+B4Crz/ycD3elpE2nZUQKUlauY1pDQAAoGkh8PojD+fxSlK/Mx2jvCt+PVD/9QAAAPgwAq8/qsUV1zhxDQAANFUEXn/kuuLaL1JJzS4o0TslVkEWQzsPFmnngaKGqw0AAMDHEHj9UWSC48Q1017jE9ea2YJ0btvmkqQVzOMFAABNCIHXX9VqWoNzHi+BFwAANB0EXn9VhxPXVm47ILud5ZcBAEDTQOD1V7UY4e2e1FwRIVYdLCzVptyCBikLAADA1xB4/VXlE9dKC2vUJdhqUXp7x2oNK1meDAAANBEEXn8VmSA1S/DoxDVJ6tvBEXi/Zh4vAABoIgi8/qwW83jPT3XM412dc1Al5RX1XxMAAICPIfD6s1rM4+0UH6m4ZiE6Wlah9TsPNURVAAAAPoXA689qMcJrGMbx1RqY1gAAAJoAAq8/c47w7t9S4xPXJKlfB0fgZR4vAABoCgi8/iyqtdQs/tiJaz/WuFu/Y/N4v/9vvg4XlzVUdQAAAD6BwOvvajGPt03zMKXERajCburb3w42SFkAAAC+gsDr72oxj1dieTIAANB0EHj9XS1GeCXp/GMnrq0g8AIAgABH4PV3iec67vdt9ujEtYwOsTIMaeveI8orKG6g4gAAALyPwOvvanniWvPwEHVrEy1JWrmNUV4AABC4CLyBoJbTGvo6lyfbeqB+6wEAAPAhBN5AUMsT1yrP4zVNs35rAgAA8BEE3kBQyxHensktFBJkUW5BsX7bX/P5vwAAAP6EwBsInCO8+zZLpUU17hYabFXPdi0ksVoDAAAIXATeQBDZWopo5ThxLa/mJ65JUr8znfN4CbwAACAwEXgDgWHUeR7vqt8OqLzCXr91AQAA+AACb6Co5Tzerm2iFRUapMPF5fpxd0G9lwUAAOBtBN5AUcsRXqvFUMaxywwzjxcAAAQiAm+gcI7w7tsslR31qOv5zOMFAAABjMAbKKISpYiWklnh0RXXpOMnrq3d8YeOllY0RHUAAABeQ+ANFIZR63m8KXERah0dqtIKu9bsOFjvpQEAAHgTgTeQJJ7ruN+93qNuhmEcX56MebwAACDAEHgDSS1PXJPcLzMMAAAQSAi8gaQOJ671PbZSw0+7C/RHYWk9FwYAAOA9BN5AUocT11pFhapjfDOZpuMiFAAAAIGCwBtI6nDimiTm8QIAgIBE4A009TCPdyWBFwAABBACb6Cpwwhv75QYWS2Gth8o0q6DRfVaFgAAgLcQeAONc4R37yaPT1yLDA1W96TmkqSV2xjlBQAAgYHAG2ii2kjhcY4T1/J+8rj78Xm8nLgGAAACA4E30BhGpXm8nl2AQpL6HVuebOWv+2W3m/VYGAAAgHcQeANRHebxntu2hcKCrTpQWKoteYfrtSwAAABvIPAGItcI7/cedw0Jsii9fYwkrroGAAACA4E3ELmuuOb5iWsSlxkGAACBhcAbiKLPkMJjJXt5rU5c69vBEXi/zTmo0nJ7fVcHAADQqAi8gcgwpMRzHY9rceLaWQmRio0IUVFphTbsOlS/tQEAADQyAm+gqsOJaxaLob5cZhgAAAQIAm+gqsOJa5L78mQAAAD+jMAbqNxOXCv2uLvzAhTrdx3S4eKyeiwMAACgcflE4J01a5aSk5MVGhqq9PR0rV69+pTtFyxYoLPOOkuhoaHq1q2bPvzwQ9drZWVluv/++9WtWzdFREQoMTFRN910k3bv3t3Qh+Fb6njiWlJMuNrFhqvCbmp1zsEGKBAAAKBxeD3wvvnmm8rOztaUKVO0bt06paWlKSsrS3v37q22/cqVKzVixAjdcsstWr9+vYYMGaIhQ4boxx9/lCQVFRVp3bp1mjx5statW6d33nlHW7Zs0VVXXdWYh+V9hlFpHq/nJ65Jx1drWMFlhgEAgB8zTNP06vVj09PT1atXLz3//POSJLvdrqSkJE2YMEETJ06s0n748OEqLCzU4sWLXdv69Omj7t27a/bs2dW+x3fffafevXtrx44datu27WlrKigoUHR0tPLz8xUVFVXLI/MBy6ZLXz0pnftn6ernPe7+wQ97NG7uOnWKj9THd1/YAAUCAADUjid5zasjvKWlpVq7dq0yMzNd2ywWizIzM7Vq1apq+6xatcqtvSRlZWWdtL0k5efnyzAMNW/evNrXS0pKVFBQ4HYLCHVYqUGSMjrEyjCkLXmHtfew5/OAAQAAfIFXA+/+/ftVUVGh+Ph4t+3x8fHKzc2ttk9ubq5H7YuLi3X//fdrxIgRJ03/M2bMUHR0tOuWlJRUi6PxQc6VGvbW7sS1mIgQdUl0fGYrmdYAAAD8lNfn8DaksrIyXX/99TJNUy+++OJJ202aNEn5+fmu265duxqxygYUnSSFxThOXNvr+YlrktSvA5cZBgAA/s2rgTcuLk5Wq1V5eXlu2/Py8pSQkFBtn4SEhBq1d4bdHTt2aOnSpaec22Gz2RQVFeV2CwiGUWk93g212oVzebIVv+6Xl6d7AwAA1IpXA29ISIh69OihZcuWubbZ7XYtW7ZMGRkZ1fbJyMhway9JS5cudWvvDLtbt27Vp59+qtjY2IY5AH/gnMdbi0sMS1Kv5BiFWC3anV+snP2F9VcXAABAI/H6lIbs7Gy99NJL+ve//61Nmzbpb3/7mwoLCzVmzBhJ0k033aRJkya52t95551asmSJnnzySW3evFlTp07VmjVrNH78eEmOsHvttddqzZo1euONN1RRUaHc3Fzl5uaqtLTUK8foVUnpjvvNH0ilngfWsBCrzmvXXJK0YhvzeAEAgP/xeuAdPny4nnjiCT300EPq3r27NmzYoCVLlrhOTNu5c6f27Nnjat+3b1/NnTtXc+bMUVpamt5++20tWrRIXbt2lST9/vvveu+99/Tf//5X3bt3V+vWrV23lStXeuUYverMTKlFinT0oLT237XaxfnOaQ1bmccLAAD8j9fX4fVFAbMOr9OaV6TFd0lRbaQ7NkhBIR51X7/zDw19YaWiQoO0/qHLZLUYDVImAABATfnNOrxoJN1vlJolSAW/Sxvf8rh7tzbRigwNUkFxuX78Pb8BCgQAAGg4BN6mIMgmZYxzPP56pmSv8Ky71aI+7R0n/q3YxrQGAADgXwi8TUXPMVJoc+nAVmnz4tM2P9H5Z7IeLwAA8E8E3qbCFin1Hut4/NVTkodTt53r8X63/Q8Vl3k2QgwAAOBNBN6mJP2vUlCYtGeD9NvnHnXt0DJC8VE2lZbbtXbHHw1THwAAQAMg8DYlEXFSj1GOx1895VFXwzBco7xfM60BAAD4EQJvU5MxXrIESdu/kv67xqOuzOMFAAD+iMDb1DRPks4Z7nj89dMedXWO8G78PV+HiprgVesAAIBfIvA2Rf3ukmQ4VmvYu7nG3eKjQnVmq2YyTemb37jMMAAA8A8E3qaoZUep85WOxytmetT1fObxAgAAP0PgbarOv9txv3GBdGhnjbv1c83jZYQXAAD4BwJvU9Wmh5TSX7KXSyufq3G39PYxshhSzv5C/X7oaAMWCAAAUD8IvE3ZBdmO+3WvSUf21ahLVGiw0pKaS2K1BgAA4B8IvE1ZSn8p8TypvFj6dnaNu7E8GQAA8CcE3qbMMI6P8q5+SSouqFG3vh2Oz+M1PbxEMQAAQGMj8DZ1na6Q4jpJJfnSmpdr1OW8ds0VGmzR/iMl+iXvSAMXCAAAUDcE3qbOYpHOv8vx+JsXpLLi03axBVnVOyVWEsuTAQAA30fghdTtOinqDOlInrThjRp1Of9MR+BlHi8AAPB1BF5I1mCp7wTH4xXPSBXlp+3inMf77W8HVFZhb8jqAAAA6oTAC4fzbpLCY6VDO6SfF522+dmto9QiPFiFpRX6ftehBi8PAACgtgi8cAgJl9L/5nj89dPSaVZfsFgM9eUywwAAwA8QeHFc779IIc2kvB+lrZ+ctnm/DqzHCwAAfB+BF8eFtZB63ux4/NVTp23uvADF+p2HdLi4rCErAwAAqDUCL9xljJOsNmnXN9KOlads2jY2XClxESq3m5r4zkbZ7VyEAgAA+B4CL9xFJkjdb3Q8rsEo7z+GdlOw1dAHP+zR459saeDiAAAAPEfgRVX97pAMi/TrUmnPD6dsmtEhVjOGnSNJenH5Ns1bvbMxKgQAAKgxAi+qimkvdRnqeLxi5mmbX9vjDN0xIFWS9OCiH/XlL/sasDgAAADPEHhRvfPvdtz/tFA6sO20ze/OTNXQc9uowm7q9jfWaUvu4QYuEAAAoGYIvKheQjcp9TLJtEsrnz1tc8Mw9D/XdFPvlBgdKSnXmFdWa29BcSMUCgAAcGoEXpzc+dmO+w1zpYI9p21uC7Jqzp97qH3LCO3OL9Yt/16jotLTX6YYAACgIRF4cXLtMqS2GVJFqfTNrBp1aR4eoldG91JMRIg2/p6vO+atVwXLlQEAAC8i8OLUnHN517wiHf2jRl3axUbopZt6KiTIok837dXDi39uwAIBAABOjcCLU0u9TIrvKpUekVb/q8bderRroaev7y5JenXldr2yIqeBCgQAADg1Ai9OzTCOj/J++6JUWlTjrlec01r3DzxLkjR98c9a+nNeQ1QIAABwSgRenN7ZQ6QWyVLRAWndax51va1/e43onSTTlO6Yt14b/5vfICUCAACcDIEXp2cNkvrd6Xi88jmpvLTGXQ3D0PSru+qC1DgdLavQzf/+Tr8fOtpAhQIAAFRF4EXNpN0oNYuXCv4rbVzgUddgq0UvjDxPZyVEat/hEt38yncqKC5roEIBAADcEXhRM8GhUsY4x+MVMyW73aPukaHBenl0L7WKtGlL3mGNe2Odyio82wcAAEBtEHhRcz3GSKHR0v5fpM2LPe6e2DxML4/upfAQq77aul+TF/0o02SNXgAA0LAIvKi50Cip162Ox18/LdUirHZtE63nRpwriyHN/26XXvxiWz0XCQAA4I7AC8/0+ZsUFCbtXiflfFGrXQzoHK+HrjxbkvTYki16//vd9VkhAACAGwIvPBMRJ513k+PxV0/Vejej+6VoTL9kSdI9C77Xmu0H66E4AACAqgi88FzfCZIlyDHC+/vaWu/mwSvO1qVnx6u03K5bX1uj7fsL67FIAAAABwIvPNc8Sep2veNxHUZ5rRZDz9zQXeecEa0/iso05tXv9Edhzdf4BQAAqAkCL2rn/Lsc95sXS/u21Ho34SFB+teonmrTPEw5+wv119fXqqS8on5qBAAAEIEXtdWyk3TWlY7HK56p065aRYbqlTG9FGkL0urtB/X3t39guTIAAFBvCLyovfOzHfcb5kqz+khv3yx9+YS05SPpjx0eLVvWMT5SL/6ph4Isht7dsFtPL/2lgYoGAABNjWEylFZFQUGBoqOjlZ+fr6ioKG+X49veGiX9vKj610IipVadpfizpVZdjt2fLYXHnHR3b363U/f/30ZJ0uPXnqPreiY1QNEAAMDfeZLXCLzVIPB6wDSlgt+lvJ+lvT8du//ZMa/XXlZ9n8jE4+E3vovjvmUnKcgmSXpsyWa9sHybgiyGXru5t/qeGdeIBwQAAPwBgbeOCLz1oKJMOvCrlPeTIwDn/ex4nL+z+vaGVYo9U4o/W/aWZ+ulX0L1n5xmyre11u0Xd5TVMGTYyxVkL1ZQRbGC7CWOx67nxbJWlJzw/Fi7Cvc+1orj/WRYVGZrofLQWFWExcgeFiszPE5GszhZI1rKGhmn4MhWCg0LV2iwRaFBVlksRuN+lgAAoAq/C7yzZs3S448/rtzcXKWlpem5555T7969T9p+wYIFmjx5srZv367U1FT985//1OWXX+563TRNTZkyRS+99JIOHTqkfv366cUXX1RqamqN6iHwNqDiAmnvJvfR4LyfpOJD1TYvMm0ql0VhKlWw4b3VGw6bYTpoRuqgonRQ0co3olRgidYRa3MVBjVXUXBzFQe3UHFIjMpsLWTYIhQaZFV4iFXhNqsiQoIcj0OCFGE7dh9iVbjNuf1YG5tVIVaLDINQDQDAqXiS14IaqaaTevPNN5Wdna3Zs2crPT1dM2fOVFZWlrZs2aJWrVpVab9y5UqNGDFCM2bM0JVXXqm5c+dqyJAhWrdunbp27SpJeuyxx/Tss8/q3//+t1JSUjR58mRlZWXp559/VmhoaGMfIioLjZLapjtuTqYpHd7jPi0i7yeZ+7covKKk2t2UGKEqs9hUZthUaglVmRFy7N6mMotNpa77UJU621Xa5mwju1220oMKK/9D4WWHFFFxSJEV+Yqy56u5ma9o87CCjQpFGkcVaRxVO+2tVLek8mO3Yvf6ikybDipSJWawyhSkCllUJqvKnY9Nq0oVpCJZVK4glcui8mOv22WVaQ2SYQmWYQ2SYQ2WJShYFmuwLEEhsgYFKygoWBZrkGRIkkWmjGOPDcfNcNwMSaYMGYZxrI3zdWdby7HHOt7Prf+x141jIfzY64Zhce3DsFiO9bE4+hy7OduZlbe5Hltc7+N6bkgWw5Api6v98T4W1/EYbn0qvZfFsc0wDBmOnUmyyLAYbnUahiGLxer4XCzOthbXPh3vaXEcqiyOfs7XjvWxWCyuz9WwHN9uHHs/5/sbMhwfpbNuOY7R9RFX2u54bsj5t07l51Xa8QcRAHjE6yO86enp6tWrl55//nlJkt1uV1JSkiZMmKCJEydWaT98+HAVFhZq8eLFrm19+vRR9+7dNXv2bJmmqcTERN1zzz269957JUn5+fmKj4/Xq6++qhtuuOG0NTHC6yMqyqRDx6ZABIdJQaFScLhjrm9j/R++aUrFh1RxZL9K8/NUfnivyo/sl3lkn8zCAzKK9sty9ICsRw8ouOSggksOynqyuctocuymIVOOPzocN8djHXtsl6XK63Ldn7i9arvj25z7Pd7f/fnxfUiGTOOE59Xss8q94V575b5ubQ2jymvHX6+8n2N/jFU6LucfUZVrkfOPNVefSnU6/0Cr/JpRuR7HvgwZMl37PvaeRuV+hvOt3D43VXNMrobO55X/YDyhrfPYdGJ/136cn43l2HtX6neq96x2m9xrqfQ5OPfnqueENu5/BJ94fNX9b61x7DN17lNVPlP3/VTdt3Hie1V+f2fdJ3y27v3d25iuPVb9TqqrpfJ37b6vk/Sp8h2e+IfnCZ/TSV6r+sfq6d6v+n0Z1bRxfgKm20uV21RemMuo8tD9vzvHluP7rHwMlZtUrc0aEq60S65TY/CbEd7S0lKtXbtWkyZNcm2zWCzKzMzUqlWrqu2zatUqZWdnu23LysrSokWLJEk5OTnKzc1VZmam6/Xo6Gilp6dr1apV1QbekpISlZQcH0ksKCioy2GhvliDpdgO3q3BMKSwFrKGtVBYyxpMiTFNqeSwVLRfKjoolZc4Tt6zl0sV5Y7HFWWSvaLS43LJXq6K8lKVlZWqrNRxX15WpvKyElWUl6m8vEwVZaWyl5epoqJMZnmZTHuFXHHHdEQcV9mu55VfdxXp/rpZOU457p37c/SVDNmr3+a2r2PxwrQf/5/ISn2ME/dbqU63qGdWjn2Vo5HjNaPSa8fbVYpt5vHHlW+SZNHx2iwnREWr7Kf/fj1kMY5/tn6vpocQAIcKoPbyFCs1UuD1hFcD7/79+1VRUaH4+Hi37fHx8dq8eXO1fXJzc6ttn5ub63rdue1kbU40Y8YMTZs2rVbHALgxDMe0jdAoKaa9R12tx25MuvEy81joNh2B/pSPq9zL8foJr5mmXabdLtN0PLbbTZmu/ZmO12SXeWy78x/eTPuxe9PRV6bjNVcbZ7tK211tTLtM89iojdt+zUr7k5x/+Bx/L1Om7JUOyXHMx/vK9R6G4x1lHjtms9L+ZJrHdn+8VudzOfdf6fnx9zp+/Mc/v+PPXccoU4ZrH3bX/g0dr8NZs/u+jr+P+z7l3tbZvvJ/F85jddtW+T1UzXvKrV/l+k5s4zquY21cY2em/fgoqqu93fWeld680uPq3uP4Z+TWtnKbE7dXqqEyo5p9n7T/SfZpmNX8kWme2K6axydpY5gn61d13876Xf/NnNDfua1y/e5js9Udn/u/f5zsOAy30qp+NpX34fjvoJpjkXlCPcf2YVZXx6nqrb7NyY7DcHtaffvikBZyT2C+wetzeH3BpEmT3EaNCwoKlJTE+q9Ak+Saq1x/1+U54R96AQCNzKtXWouLi5PValVeXp7b9ry8PCUkJFTbJyEh4ZTtnfee7NNmsykqKsrtBgAAgMDg1cAbEhKiHj16aNmyZa5tdrtdy5YtU0ZGRrV9MjIy3NpL0tKlS13tU1JSlJCQ4NamoKBA33777Un3CQAAgMDl9SkN2dnZGjVqlHr27KnevXtr5syZKiws1JgxYyRJN910k9q0aaMZM2ZIku688071799fTz75pK644grNnz9fa9as0Zw5cyQ5zoC866679Mgjjyg1NdW1LFliYqKGDBnircMEAACAl3g98A4fPlz79u3TQw89pNzcXHXv3l1LlixxnXS2c+dOWSzHB6L79u2ruXPn6sEHH9QDDzyg1NRULVq0yLUGryT9/e9/V2FhocaOHatDhw7p/PPP15IlS1iDFwAAoAny+jq8voh1eAEAAHybJ3nNq3N4AQAAgIZG4AUAAEBAI/ACAAAgoBF4AQAAENAIvAAAAAhoBF4AAAAENK+vw+uLnCu1FRQUeLkSAAAAVMeZ02qywi6BtxqHDx+WJCUlJXm5EgAAAJzK4cOHFR0dfco2XHiiGna7Xbt371ZkZKQMw5Dk+CsiKSlJu3bt4mIUAYLvNDDxvQYevtPAw3camBr7ezVNU4cPH1ZiYqLbVXmrwwhvNSwWi84444xqX4uKiuLHGWD4TgMT32vg4TsNPHyngakxv9fTjew6cdIaAAAAAhqBFwAAAAGNwFtDNptNU6ZMkc1m83YpqCd8p4GJ7zXw8J0GHr7TwOTL3ysnrQEAACCgMcILAACAgEbgBQAAQEAj8AIAACCgEXgBAAAQ0Ai8NTBr1iwlJycrNDRU6enpWr16tbdLQh1MnTpVhmG43c466yxvlwUPfPnllxo8eLASExNlGIYWLVrk9rppmnrooYfUunVrhYWFKTMzU1u3bvVOsaix032vo0ePrvLbHThwoHeKRY3MmDFDvXr1UmRkpFq1aqUhQ4Zoy5Ytbm2Ki4s1btw4xcbGqlmzZrrmmmuUl5fnpYpxOjX5Ti+66KIqv9XbbrvNSxU7EHhP480331R2dramTJmidevWKS0tTVlZWdq7d6+3S0MddOnSRXv27HHdvv76a2+XBA8UFhYqLS1Ns2bNqvb1xx57TM8++6xmz56tb7/9VhEREcrKylJxcXEjVwpPnO57laSBAwe6/XbnzZvXiBXCU1988YXGjRunb775RkuXLlVZWZkuu+wyFRYWutrcfffdev/997VgwQJ98cUX2r17t4YNG+bFqnEqNflOJenWW291+60+9thjXqr4GBOn1Lt3b3PcuHGu5xUVFWZiYqI5Y8YML1aFupgyZYqZlpbm7TJQTySZCxcudD232+1mQkKC+fjjj7u2HTp0yLTZbOa8efO8UCFq48Tv1TRNc9SoUebVV1/tlXpQP/bu3WtKMr/44gvTNB2/zeDgYHPBggWuNps2bTIlmatWrfJWmfDAid+paZpm//79zTvvvNN7RVWDEd5TKC0t1dq1a5WZmenaZrFYlJmZqVWrVnmxMtTV1q1blZiYqPbt22vkyJHauXOnt0tCPcnJyVFubq7b7zY6Olrp6en8bgPA8uXL1apVK3Xq1El/+9vfdODAAW+XBA/k5+dLkmJiYiRJa9euVVlZmdvv9ayzzlLbtm35vfqJE79TpzfeeENxcXHq2rWrJk2apKKiIm+U5xLk1Xf3cfv371dFRYXi4+PdtsfHx2vz5s1eqgp1lZ6erldffVWdOnXSnj17NG3aNF1wwQX68ccfFRkZ6e3yUEe5ubmSVO3v1vka/NPAgQM1bNgwpaSkaNu2bXrggQc0aNAgrVq1Slar1dvl4TTsdrvuuusu9evXT127dpXk+L2GhISoefPmbm35vfqH6r5TSbrxxhvVrl07JSYm6ocfftD999+vLVu26J133vFarQReNDmDBg1yPT7nnHOUnp6udu3a6a233tItt9zixcoAnMoNN9zgetytWzedc8456tChg5YvX64BAwZ4sTLUxLhx4/Tjjz9yzkQAOdl3OnbsWNfjbt26qXXr1howYIC2bdumDh06NHaZkjhp7ZTi4uJktVqrnC2al5enhIQEL1WF+ta8eXN17NhRv/76q7dLQT1w/jb53Qa+9u3bKy4ujt+uHxg/frwWL16szz//XGeccYZre0JCgkpLS3Xo0CG39vxefd/JvtPqpKenS5JXf6sE3lMICQlRjx49tGzZMtc2u92uZcuWKSMjw4uVoT4dOXJE27ZtU+vWrb1dCupBSkqKEhIS3H63BQUF+vbbb/ndBpj//ve/OnDgAL9dH2aapsaPH6+FCxfqs88+U0pKitvrPXr0UHBwsNvvdcuWLdq5cye/Vx91uu+0Ohs2bJAkr/5WmdJwGtnZ2Ro1apR69uyp3r17a+bMmSosLNSYMWO8XRpq6d5779XgwYPVrl077d69W1OmTJHVatWIESO8XRpq6MiRI24jBTk5OdqwYYNiYmLUtm1b3XXXXXrkkUeUmpqqlJQUTZ48WYmJiRoyZIj3isZpnep7jYmJ0bRp03TNNdcoISFB27Zt09///nedeeaZysrK8mLVOJVx48Zp7ty5evfddxUZGemalxsdHa2wsDBFR0frlltuUXZ2tmJiYhQVFaUJEyYoIyNDffr08XL1qM7pvtNt27Zp7ty5uvzyyxUbG6sffvhBd999ty688EKdc8453ivc28tE+IPnnnvObNu2rRkSEmL27t3b/Oabb7xdEupg+PDhZuvWrc2QkBCzTZs25vDhw81ff/3V22XBA59//rkpqcpt1KhRpmk6liabPHmyGR8fb9psNnPAgAHmli1bvFs0TutU32tRUZF52WWXmS1btjSDg4PNdu3ambfeequZm5vr7bJxCtV9n5LMV155xdXm6NGj5u233262aNHCDA8PN4cOHWru2bPHe0XjlE73ne7cudO88MILzZiYGNNms5lnnnmmed9995n5+flerdswTdNszIANAAAANCbm8AIAACCgEXgBAAAQ0Ai8AAAACGgEXgAAAAQ0Ai8AAAACGoEXAAAAAY3ACwAAgIBG4AUAAEBAI/ACAE7KMAwtWrTI22UAQJ0QeAHAR40ePVqGYVS5DRw40NulAYBfCfJ2AQCAkxs4cKBeeeUVt202m81L1QCAf2KEFwB8mM1mU0JCgtutRYsWkhzTDV588UUNGjRIYWFhat++vd5++223/hs3btQll1yisLAwxcbGauzYsTpy5Ihbm5dfflldunSRzWZT69atNX78eLfX9+/fr6FDhyo8PFypqal67733GvagAaCeEXgBwI9NnjxZ11xzjb7//nuNHDlSN9xwgzZt2iRJKiwsVFZWllq0aKHvvvtOCxYs0KeffuoWaF988UWNGzdOY8eO1caNG/Xee+/pzDPPdHuPadOm6frrr9cPP/ygyy+/XCNHjtTBgwcb9TgBoC4M0zRNbxcBAKhq9OjR+s9//qPQ0FC37Q888IAeeOABGYah2267TS+++KLrtT59+ui8887TCy+8oJdeekn333+/du3apYiICEnShx9+qMGDB2v37t2Kj49XmzZtNGbMGD3yyCPV1mAYhh588EE9/PDDkhwhulmzZvroo4+YSwzAbzCHFwB82MUXX+wWaCUpJibG9TgjI8PttYyMDG3YsEGStGnTJqWlpbnCriT169dPdrtdW7ZskWEY2r17twYMGHDKGs455xzX44iICEVFRWnv3r21PSQAaHQEXgDwYREREVWmGNSXsLCwGrULDg52e24Yhux2e0OUBAANgjm8AODHvvnmmyrPO3fuLEnq3Lmzvv/+exUWFrpeX7FihSwWizp16qTIyEglJydr2bJljVozADQ2RngBwIeVlJQoNzfXbVtQUJDi4uIkSQsWLFDPnj11/vnn64033tDq1av1//7f/5MkjRw5UlOmTNGoUaM0depU7du3TxMmTNCf//xnxcfHS5KmTp2q2267Ta1atdKgQYN0+PBhrVixQhMmTGjcAwWABkTgBQAftmTJErVu3dptW6dOnbR582ZJjhUU5s+fr9tvv12tW7fWvHnzdPbZZ0uSwsPD9fHHH+vOO+9Ur169FB4ermuuuUZPPfWUa1+jRo1ScXGxnn76ad17772Ki4vTtdde23gHCACNgFUaAMBPGYahhQsXasiQId4uBQB8GnN4AQAAENAIvAAAAAhozOEFAD/FjDQAqBlGeAEAABDQCLwAAAAIaAReAAAABDQCLwAAAAIagRcAAAABjcALAACAgEbgBQAAQEAj8AIAACCg/f+0Is5vC23ocgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout test: loss=0.000160 | rmse=0.012654 | mae=0.009617\n",
      "Tenor : 25; Maturity : 30 | val_rmse=0.012989, val_mae=0.010500 | test_rmse=0.013053, test_mae=0.010110\n",
      "Tenor : 30; Maturity : 30 | val_rmse=0.012779, val_mae=0.009690 | test_rmse=0.012243, test_mae=0.009124\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hist_df = pd.DataFrame(history, columns=[\"epoch\", \"train_loss\", \"val_loss\", \"val_rmse\", \"val_mae\"])\n",
    "display(hist_df.tail())\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(hist_df[\"epoch\"], hist_df[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(hist_df[\"epoch\"], hist_df[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Training Curves\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "_, _, _, val_preds, val_targets = evaluate(model, val_loader, loss_fn)\n",
    "test_loss, test_rmse, test_mae, test_preds, test_targets = evaluate(model, test_loader, loss_fn)\n",
    "\n",
    "print(f\"Holdout test: loss={test_loss:.6f} | rmse={test_rmse:.6f} | mae={test_mae:.6f}\")\n",
    "\n",
    "for i, target_name in enumerate(TARGET_COLS):\n",
    "    rmse_val_i = mean_squared_error(val_targets[:, i], val_preds[:, i]) ** 0.5\n",
    "    mae_val_i = mean_absolute_error(val_targets[:, i], val_preds[:, i])\n",
    "    rmse_test_i = mean_squared_error(test_targets[:, i], test_preds[:, i]) ** 0.5\n",
    "    mae_test_i = mean_absolute_error(test_targets[:, i], test_preds[:, i])\n",
    "    print(\n",
    "        f\"{target_name} | \"\n",
    "        f\"val_rmse={rmse_val_i:.6f}, val_mae={mae_val_i:.6f} | \"\n",
    "        f\"test_rmse={rmse_test_i:.6f}, test_mae={mae_test_i:.6f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872b4ade",
   "metadata": {},
   "source": [
    "## 10) Export Holdout Test Predictions\n",
    "\n",
    "This exports predictions for the internal holdout test split to `notebooks/baseline_holdout_predictions.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "583b9e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: baseline_holdout_predictions.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e7297823-9ff6-4d60-865e-f7ef688dc8d2\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred_Tenor : 25; Maturity : 30</th>\n",
       "      <th>true_Tenor : 25; Maturity : 30</th>\n",
       "      <th>pred_Tenor : 30; Maturity : 30</th>\n",
       "      <th>true_Tenor : 30; Maturity : 30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.340711</td>\n",
       "      <td>0.344334</td>\n",
       "      <td>0.330527</td>\n",
       "      <td>0.332519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.359338</td>\n",
       "      <td>0.374207</td>\n",
       "      <td>0.341158</td>\n",
       "      <td>0.356600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.337534</td>\n",
       "      <td>0.339023</td>\n",
       "      <td>0.327345</td>\n",
       "      <td>0.327683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.390145</td>\n",
       "      <td>0.395039</td>\n",
       "      <td>0.370026</td>\n",
       "      <td>0.369895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.361217</td>\n",
       "      <td>0.338692</td>\n",
       "      <td>0.342927</td>\n",
       "      <td>0.324837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7297823-9ff6-4d60-865e-f7ef688dc8d2')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e7297823-9ff6-4d60-865e-f7ef688dc8d2 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e7297823-9ff6-4d60-865e-f7ef688dc8d2');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   id  pred_Tenor : 25; Maturity : 30  true_Tenor : 25; Maturity : 30  \\\n",
       "0   0                        0.340711                        0.344334   \n",
       "1   1                        0.359338                        0.374207   \n",
       "2   2                        0.337534                        0.339023   \n",
       "3   3                        0.390145                        0.395039   \n",
       "4   4                        0.361217                        0.338692   \n",
       "\n",
       "   pred_Tenor : 30; Maturity : 30  true_Tenor : 30; Maturity : 30  \n",
       "0                        0.330527                        0.332519  \n",
       "1                        0.341158                        0.356600  \n",
       "2                        0.327345                        0.327683  \n",
       "3                        0.370026                        0.369895  \n",
       "4                        0.342927                        0.324837  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    holdout_pred = model(X_test_t.to(DEVICE)).cpu().numpy()\n",
    "\n",
    "id_candidates = [c for c in [\"id\", \"ID\", \"row_id\", \"index\"] if c in test_df.columns]\n",
    "if id_candidates:\n",
    "    out = pd.DataFrame({id_candidates[0]: test_df[id_candidates[0]].values})\n",
    "else:\n",
    "    out = pd.DataFrame({\"id\": np.arange(len(test_df))})\n",
    "\n",
    "for i, col in enumerate(TARGET_COLS):\n",
    "    out[f\"pred_{col}\"] = holdout_pred[:, i]\n",
    "    out[f\"true_{col}\"] = y_test[:, i]\n",
    "\n",
    "output_path = \"baseline_holdout_predictions.csv\"\n",
    "out.to_csv(output_path, index=False)\n",
    "print(\"Saved:\", output_path)\n",
    "display(out.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7bd55d",
   "metadata": {},
   "source": [
    "## 11) Next Steps for Improvement\n",
    "\n",
    "- Set `TARGET_COLS` manually if auto-detection picks the wrong columns.\n",
    "- Tune `n_modes`, `n_photons`, grouping size, and projection width.\n",
    "- Try log-target transformation if price scales are wide.\n",
    "- Add k-fold validation for more robust model selection.\n",
    "- Compare against a classical baseline (MLP/XGBoost) to quantify QML lift.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
