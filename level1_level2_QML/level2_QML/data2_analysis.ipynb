{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67af2c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Level 2 — Missing Data EDA\n",
    "Understand exactly what is missing, where, and what patterns exist\n",
    "to inform the model architecture.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d02ec2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LEVEL 2 — MISSING DATA ANALYSIS\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────\n",
    "# 1. LOAD BOTH DATASETS\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "ds1 = load_dataset(\"Quandela/Challenge_Swaptions\",\n",
    "                   data_files=\"level-1_Future_prediction/train.csv\", split=\"train\")\n",
    "ds2 = load_dataset(\"Quandela/Challenge_Swaptions\",\n",
    "                   data_files=\"level-2_Missing_data_prediction/train_level2.csv\", split=\"train\")\n",
    "\n",
    "df1 = ds1.to_pandas()\n",
    "df2 = ds2.to_pandas()\n",
    "\n",
    "df1[\"Date\"] = pd.to_datetime(df1[\"Date\"], dayfirst=True)\n",
    "df2[\"Date\"] = pd.to_datetime(df2[\"Date\"], dayfirst=True)\n",
    "df1 = df1.sort_values(\"Date\").reset_index(drop=True)\n",
    "df2 = df2.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "feat_cols = [c for c in df2.columns if c != \"Date\"]\n",
    "tenors     = sorted(set(int(c.split(\"Tenor : \")[1].split(\";\")[0]) for c in feat_cols))\n",
    "maturities = sorted(set(float(c.split(\"Maturity : \")[1]) for c in feat_cols))\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LEVEL 2 — MISSING DATA ANALYSIS\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f15a12f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows          : 489\n",
      "Total cells         : 109536\n",
      "Missing cells       : 0\n",
      "Missing %           : 0.0%\n",
      "\n",
      "Rows with NO missing: 489\n",
      "Rows with missing   : 0\n",
      "Missing per row     : always [] cells\n",
      "\n",
      "Missing rate per MATURITY:\n",
      "  Maturity  0.08yr :   0.0%  \n",
      "  Maturity  0.25yr :   0.0%  \n",
      "  Maturity  0.50yr :   0.0%  \n",
      "  Maturity  0.75yr :   0.0%  \n",
      "  Maturity  1.00yr :   0.0%  \n",
      "  Maturity  1.50yr :   0.0%  \n",
      "  Maturity  2.00yr :   0.0%  \n",
      "  Maturity  3.00yr :   0.0%  \n",
      "  Maturity  4.00yr :   0.0%  \n",
      "  Maturity  5.00yr :   0.0%  \n",
      "  Maturity  7.00yr :   0.0%  \n",
      "  Maturity 10.00yr :   0.0%  \n",
      "  Maturity 15.00yr :   0.0%  \n",
      "  Maturity 20.00yr :   0.0%  \n",
      "  Maturity 25.00yr :   0.0%  \n",
      "  Maturity 30.00yr :   0.0%  \n",
      "\n",
      "Missing rate per TENOR:\n",
      "  Tenor  1yr :   0.0%  \n",
      "  Tenor  2yr :   0.0%  \n",
      "  Tenor  3yr :   0.0%  \n",
      "  Tenor  4yr :   0.0%  \n",
      "  Tenor  5yr :   0.0%  \n",
      "  Tenor  6yr :   0.0%  \n",
      "  Tenor  7yr :   0.0%  \n",
      "  Tenor  8yr :   0.0%  \n",
      "  Tenor  9yr :   0.0%  \n",
      "  Tenor 10yr :   0.0%  \n",
      "  Tenor 15yr :   0.0%  \n",
      "  Tenor 20yr :   0.0%  \n",
      "  Tenor 25yr :   0.0%  \n",
      "  Tenor 30yr :   0.0%  \n",
      "\n",
      "Exactly 0 columns ever have missing values:\n",
      "\n",
      "Is the missing pattern the same on every row?\n",
      "  Distinct missing patterns: 1\n",
      "  Most common pattern count: 489 rows\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────\n",
    "# 2. MISSING VALUE STRUCTURE\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "missing_per_col = df2[feat_cols].isnull().mean()\n",
    "missing_per_row = df2[feat_cols].isnull().sum(axis=1)\n",
    "\n",
    "print(f\"\\nTotal rows          : {len(df2)}\")\n",
    "print(f\"Total cells         : {len(df2) * len(feat_cols)}\")\n",
    "print(f\"Missing cells       : {df2[feat_cols].isnull().sum().sum()}\")\n",
    "print(f\"Missing %           : {df2[feat_cols].isnull().mean().mean()*100:.1f}%\")\n",
    "print(f\"\\nRows with NO missing: {(missing_per_row == 0).sum()}\")\n",
    "print(f\"Rows with missing   : {(missing_per_row > 0).sum()}\")\n",
    "print(f\"Missing per row     : always {missing_per_row[missing_per_row > 0].unique()} cells\")\n",
    "\n",
    "# Which maturities are missing?\n",
    "print(\"\\nMissing rate per MATURITY:\")\n",
    "for mat in maturities:\n",
    "    cols = [c for c in feat_cols if float(c.split(\"Maturity : \")[1]) == mat]\n",
    "    rate = df2[cols].isnull().mean().mean()\n",
    "    bar  = \"█\" * int(rate * 40)\n",
    "    print(f\"  Maturity {mat:5.2f}yr : {rate*100:5.1f}%  {bar}\")\n",
    "\n",
    "# Which tenors are missing?\n",
    "print(\"\\nMissing rate per TENOR:\")\n",
    "for ten in tenors:\n",
    "    cols = [c for c in feat_cols if int(c.split(\"Tenor : \")[1].split(\";\")[0]) == ten]\n",
    "    rate = df2[cols].isnull().mean().mean()\n",
    "    bar  = \"█\" * int(rate * 40)\n",
    "    print(f\"  Tenor {ten:2d}yr : {rate*100:5.1f}%  {bar}\")\n",
    "\n",
    "# Exactly which cells are missing?\n",
    "missing_cols = missing_per_col[missing_per_col > 0].index.tolist()\n",
    "print(f\"\\nExactly {len(missing_cols)} columns ever have missing values:\")\n",
    "for c in missing_cols[:10]:\n",
    "    print(f\"  {c}  →  {missing_per_col[c]*100:.1f}% missing\")\n",
    "if len(missing_cols) > 10:\n",
    "    print(f\"  ... and {len(missing_cols)-10} more\")\n",
    "\n",
    "# Are missing patterns consistent across rows?\n",
    "print(\"\\nIs the missing pattern the same on every row?\")\n",
    "missing_mask = df2[feat_cols].isnull()\n",
    "pattern_counts = missing_mask.apply(tuple, axis=1).value_counts()\n",
    "print(f\"  Distinct missing patterns: {len(pattern_counts)}\")\n",
    "print(f\"  Most common pattern count: {pattern_counts.iloc[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64504926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing maturities : []\n",
      "Observed maturities: 16 values\n",
      "\n",
      "Complete rows available for correlation analysis: 489\n",
      "Using Level 1 data as complete reference for correlation analysis...\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────\n",
    "# 3. CORRELATION: MISSING ROWS vs OBSERVED ROWS\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "# Get the maturity values that are missing\n",
    "missing_mats = sorted(set(\n",
    "    float(c.split(\"Maturity : \")[1])\n",
    "    for c in missing_cols\n",
    "))\n",
    "observed_mats = [m for m in maturities if m not in missing_mats]\n",
    "\n",
    "print(f\"\\nMissing maturities : {missing_mats}\")\n",
    "print(f\"Observed maturities: {len(observed_mats)} values\")\n",
    "\n",
    "# For rows that have complete data (no missing values), check correlation\n",
    "# between missing-maturity rows and neighboring observed-maturity rows\n",
    "complete_rows = df2[missing_per_row == 0]\n",
    "print(f\"\\nComplete rows available for correlation analysis: {len(complete_rows)}\")\n",
    "\n",
    "if len(complete_rows) > 10:\n",
    "    # Use Level 1 data as complete reference instead\n",
    "    print(\"Using Level 1 data as complete reference for correlation analysis...\")\n",
    "    ref = df1\n",
    "\n",
    "    for miss_mat in missing_mats:\n",
    "        miss_cols = [c for c in feat_cols if float(c.split(\"Maturity : \")[1]) == miss_mat]\n",
    "        # Nearest observed maturities\n",
    "        dists = [(abs(m - miss_mat), m) for m in observed_mats]\n",
    "        dists.sort()\n",
    "        nearest = [d[1] for d in dists[:3]]\n",
    "        print(f\"\\n  Maturity {miss_mat}yr ← correlates with:\")\n",
    "        for near_mat in nearest:\n",
    "            near_cols = [c for c in feat_cols if float(c.split(\"Maturity : \")[1]) == near_mat]\n",
    "            # Average correlation across tenors\n",
    "            corrs = []\n",
    "            for mc, nc in zip(miss_cols, near_cols):\n",
    "                if mc in ref.columns and nc in ref.columns:\n",
    "                    corrs.append(ref[mc].corr(ref[nc]))\n",
    "            print(f\"    Maturity {near_mat}yr  →  avg corr = {np.mean(corrs):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9a5318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL TASK SUMMARY\n",
      "============================================================\n",
      "  Input  (observed): 224 cells per row\n",
      "  Output (to predict): 0 cells per row\n",
      "  Ratio: predict 0.0% of surface from 100.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "obs_cols  = [c for c in feat_cols if c not in missing_cols]\n",
    "pred_cols = missing_cols\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"MODEL TASK SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Input  (observed): {len(obs_cols)} cells per row\")\n",
    "print(f\"  Output (to predict): {len(pred_cols)} cells per row\")\n",
    "print(f\"  Ratio: predict {len(pred_cols)/len(feat_cols)*100:.1f}% of surface from {len(obs_cols)/len(feat_cols)*100:.1f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
